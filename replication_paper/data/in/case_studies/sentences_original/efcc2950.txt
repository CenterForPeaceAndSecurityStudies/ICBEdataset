We trace this failure to the key features of the CIA’s identity and culture.
We provide a unified understanding of surprises that does not conflict with prevailing theories, but is logically prior to them because the identity and cultural features of the organization create the antecedent conditions that enable these theories to operate.
No episode in the history of international relations has received such scrutiny from so many historians, political scientists and organizational theorists as this crisis.
Indeed, Allison’s landmark book, “Essence of Decision”, considers nothing else.
The crisis began on October 16, 1962 at 8:45 A.M, when President Kennedy was informed that hard photographic evidence had been obtained showing Soviet nuclear ballistic missiles installed in Cuba.
Despite such interest by scholars, Allison and Zelikow observe that even the central questions have eluded satisfactory answers.
Perhaps the most important of these questions is why the Soviet operation took the United States by surprise and therefore developed into a crisis in the first place.
Indeed, for months, as the massive and highly secret operation was carried out on the Soviet and Cuban sides, and despite mounting factual evidence, the CIA had assured the President that the Soviet would 2 #14179 never install nuclear missiles outside its territory.
Scholars studying strategic surprises have developed three main theories.
Signal-to-noise theory advances that surprises result from the inability to pick so-called ‘weak signals’ that foretell surprises.
Theories on bureaucratic politics (Allison & Zelikow, 1999; Allison, 1971; Zegart, 2005) explain surprises through the lenses of organizational conflicts.
Although these theories rarely contradict one another, they are unable to explain the phenomenon of strategic surprise as a whole.
A reason for this is that these theories ignore cultural factors – the vast majority assumes that the specific identities and cultures of intelligence organizations and analysts are unproblematic.
Ever since Max Weber’s seminal work, however, social scientists have recognized that regularities in organizational behavior must be understood in terms of the organization’s cultural setting.
Because intelligence analysis is permeated by social facts , it is firmly in the grip of the identity and culture of the analyzing organization.
We suggest that by examining these endogenous features of the CIA, one can better understand how strategic surprises occur.
We contribute to the research on surprises by providing a unified understanding of surprises that does not conflict with prevailing theories, but is logically prior to them because the identity and cultural features we reveal create the antecedent conditions at the CIA that enable these theories to operate.
Then, we identity four key features of the CIA’s identity and culture and show how they distort the intelligence cycle – the very process of what the CIA does – and thus lead to surprises.
By linking these features to the distortion of the intelligence cycle, we show how strategic surprises are socially constructed.
We then discuss these findings and how they relate to prevailing explanations of surprise.
It is therefore important to proceed with a carefully chosen definition.
We define strategic surprise as the sudden realization that one has been operating on the basis of an erroneous assessment which results in a failure to anticipate an event that has a significant impact on vital interests.
A strategic surprises, in that sense, corresponds to Weick’s ‘cosmology episodes’, when people “suddenly and deeply feel that the universe is no longer a rational, orderly system.” but we place it at the organizational level.
Importantly, our definition marks two important shifts in the theoretical focus.
The first is a shift away from the event itself toward the organization experiencing the surprise.
This helps distinguish the event from its interpretation as a crisis, an opportunity, or catastrophe , and from its effects.
Even if a surprise has positive consequences, the fact that it is a surprise is inherently problematic from an organizational point of view.
Ascribing the origin of strategic surprises to erroneous assessments is interesting because it allows the adoption of a clear conceptual definition of what dysfunction should mean.
A surprise stands in contrast to effective forecasts , and to measures designed to prevent, mitigate, or even exploit future events.
Following Barnett and Finnemore , our vantage point for judging dysfunction is the publicly proclaimed mission of the organization.
Accordingly, in the case of the CIA, dysfunction is not an inability to predict everything accurately, but an inability to provide effective forecasts.
A strategic surprise is conceptually different from several similar concepts.
The jolt he studied was a sudden doctors’ strike that triggered organizational learning and change in a 5 #14179 hospital but, unlike a strategic surprise, did not affect the hospital’s vital interests.
The third concept is ‘rare event’ (Christianson, Farkas, Sutcliffe, & Weick, 2009; Lampel, Shamsie, & Shapira, 2009) a term employed to describe events that occur outside the everyday experience of an organization.
However, the term rare is problematic in our context as it relates to the frequency of the event rather than its inherent uniqueness.
Some events, such as the Olympic Games or annual business results publication, are rare but perfectly predictable, and they can be repeated or recurring.
An example of weak signal, in the case of Cuba, was the unprecedented influx of Soviet bloc personnel and equipment in Cuba, indicating that something new and different was taking place, reported by the CIA on August 22nd, 1962.
Winter drew inspiration from biological organisms to explore how organizations can improve the sensing and detection of weak signals.
In her study of the Japanese attack on Pearl Harbor in December 1941, however, Wohlstetter put forth the notion that the Japanese attack succeeded because of a lack of signals.
In their study of surprises in business contexts, Bar Joseph and Sheaffer follow Wohlstetter and focus on the role of hypotheses in sorting signals from noise.
In the example above, while the unprecedented influx of Soviet bloc personnel and equipment in Cuba was noted by the CIA, it was dismissed as the Agency hung to its hypothesis that the Soviets would not install nuclear missiles in Cuba.
Viewed as an exogenous phenomenon, it is not analyzed in detail and is explained away.
Cybernetic explanations, hence, fail to recognize that in the analysis of weak signals, hypotheses are the starting point.
This poses the question of how hypotheses are generated, adopted or rejected by analysts, and directs the investigation toward the individual dimension.
Jervis , Heuer , Kahneman, Slovic, and Tversky , and others have underlined the importance of psychological factors in strategic surprise and stressed the role of heuristic shortcuts in information processing.
According to Walsh , individuals meet the information challenge by applying knowledge structures 7 #14179 to their information worlds.
Such structures facilitate information processing and decision making, but they can also blind individuals to important changes in their environment.
Jervis explored how human needs and emotional states alter information processing through motivational biases.
Janis’s work on group think, which stressed the emotional dynamics and pressures for cooperation in small groups, also largely dealt with mental processes.
Similarly, Lampel and Shapira study the surprise switch by a partner from a cooperative to predatory behavior in the context of buyer-supplier relationships, and attribute this surprise to a judgmental error when interpreting information gathered from their environment.
First, they concentrate on the ‘hot’ biases and do not effectively consider long-term processes of cumulative causation in a structured manner.
Second, their focus is on the moment of information processing,e. the analysis step.
Third, much of the psychologically oriented literature is built around individual analysis and decisions.
As Levine and Resnick observed, cognition is almost always collaborative.
Therefore, the key challenge is to account for the role of social processes in the acquisition, retention, and retrieval of information and collective dynamics must be captured at the organizational level.
As noted earlier, Allison’s work is essentially ‘after the fact’ and does not explicitly advance a theory of strategic surprise, but his work on the Cuban missile crisis has had a substantial impact on thinking about the topic.
Allison and Zelikow’s revised Model Two, Organizational Behavior, is especially 8 #14179 pertinent because it evolved to account for the role of organizational culture and explored how culture can affect intelligence analysis.
Allison’s Model Three, Bureaucratic Politics, has also contributed to the topic, though usually from the perspective of failures among agencies to cooperate, share or transmit information.
Discussions of the politicization of intelligence are variations on Allison and Zelikow’s theme.
Examples of organizational issues playing a part in the generation of surprises abound in the literature , but the reason for such behaviors is rarely investigated.
In addition, and on a practical level, bureaucratic politics models fail to effectively explain strategic surprises because attempts to reform intelligence structures have repeatedly been found wanting.
Paradigms and the Inevitability of Strategic Surprise Seliktar compellingly showed how Kuhn’s idea of paradigm improved our understanding of the United States foreign policy establishment’s failure to comprehend events in Iran or the Soviet Union.
However, she did not attempt to link paradigm failures to a more generalized theory of strategic surprise.
In addition, Kuhn’s approach focused on the discovery of and theorizing about natural facts.
Its application to an activity mostly concerned with social facts is problematic, however, because it does not allow us to understand how an organization fails to grasp a paradigm shift such as the unprecedented and dramatic decision by the Soviets to secretly install nuclear missiles in Cuba.
Similarly, the expression failure of imagination is also used to explain surprises away as unique, aberrant events that nobody could have imagined.
Some events are labeled as unpredictable ‘wild cards’ and Betts proposed that strategic surprises are, in fact, inevitable.
He attributed this inevitability to “paradoxes of perception,” which consist of the irresolvable trade-offs and dilemmas inherent in attempts to improve strategic warning.
Identity and Culture Prevailing explanations of strategic surprises generally ignore cultural factors.
Allison and Zelikow (Allison & Zelikow, 1999; Allison, 1969) accounted for the role of organizational culture and explored how it can affect intelligence analysis, but they did not explore this element, thereby leaving the question open.
As intelligence analysis is permeated by social facts , however, it is firmly embedded in the identity and culture of the analyzing organization, which affect their cognition.
The case arguably addresses one of the most dramatic and important instances of strategic surprise in the United States history, that could have had catastrophic consequences.
No episode in the history of international relations has received such microscopic scrutiny from so many historian, political scientists and organizational theorists as this crisis.
In the case of Cuba, and despite considerable resources, the agency failed spectacularly to live up to its mission.
By studying the CIA, we are able to rule out explanations related to the fortuitous appearance of surprises, a lack of sensitivity or attention to a hostile environment, or a lack of resources.
The CIA’s handling of the Soviet attempt to install nuclear missiles in Cuba serves as an extreme case from which much can be learned in organization studies.
Analysis of Data In this research, we are concerned with the analytical arm of the agency, not its operational arm.
Their information worlds are extremely complex, ambiguous, and munificent , and they process huge amounts of information and try to make sense of it and produce recommendations for policy – or decision – makers.
We seek to understand the role played by identity and culture in explaining how strategic surprises occur.
In developing this understanding, we first study the case to identify fundamental, persistent features of the CIA’s identity and culture that distorted the work of the organization.
We show how these features are the key variables in an understanding of strategic surprise.
In addition, as we do not speculate about what might have happened had the CIA made a correct assessment and issued a high-quality warning to its “customers”, we specifically exclude the so-called ‘warning-warnee’ question ascribing surprises to miscommunication between intelligence producers and their customers.
In sum, we do not ask how the CIA could have stopped the Soviets from installing missiles in Cuba, but how the Agency could be surprised by the secret operation in the first place.
Data Sources and Collection Perhaps surprisingly, information from and about the CIA is abundant and easily accessible.
The critical document we refer to is Special National Intelligence Estimate Number 85-3-62 “The Military Build-up in Cuba” dated 19 September, 1962.
None of the documents used in this study was “leaked,”e., all went through the CIA’s declassification process and were, in many cases, partly redacted.
The possibility that the CIA could spin analyses of a case by selectively declassifying certain NIEs while withholding others was considered.
To counteract this possibility, these documents are looked at as individual sources in this paper, while the possible significance of redactions, declassifications, and the existence of estimates is also considered.
Furthermore, we draw on unclassified items published by the CIA for other branches of government, such as the CIA Office of Public Affairs’ A Consumer's Guide to Intelligence.
The most important of these is the CIA’s internal journal, Studies in Intelligence.
A vast number of Studies articles have been declassified, and we draw upon more than fifty of these spanning from 1955 to 2007.
Some of these articles deal directly with questions of intelligence collection and analysis, while others are employed to open a window into the CIA’s internal culture, and thereby function as our primary source for their examination.
The fourth type of source consists of scholarly work on the Cuban missile crisis, primarily the work of Allison and Zelikow which is considered a reference on the subject, as well as Fursenko and Naftali who provide an account of the crisis from the Soviet point of view.
A homogeneous body of analysts, scientism, a preference for secrets, and a drive for consensus.
A Homogeneous Body of Analysts One striking observation in the case is the fact that the CIA struggles to understand the perspectives and motivations of those it studies, here the Soviet and the Cubans.
The body of analysts is essentially made up of Caucasian, Protestant, graduates of liberal arts colleges.
Former director Robert Gates speaks of a CIA as unwilling to employ “people that are a little different, people who are eccentric, people who don’t look good in a suit and tie, people who don’t play well in the sandbox with others” The role of homogeneity and insularity – even provincialism – in the performance of analytical staff, and the link between homogeneity and analytical failings is evident in the case.
CIA analysts failed to appreciate how the Soviets assessed their own strategic situation and how they viewed Cuba.
Arguably, the pervasive scientism at the CIA would have veiled such emotional factors, thus having an effect on intelligence Tasking.
Such articles and reports provides evidence for deeply seated cultural attitudes at Langley that contributed to distorting tasking and collection, discounting human intelligence coming from Cuba dramatically, and thus links the Agency’s culture and identity to the surprise of the case.
Scientism The second reason that the CIA finds it difficult to understand the perspective and motivations of its targets is its strong positivist mindset, a tendency towards scientism, and the consistent reification of objectivity or reason.
This introduces a preference for measurable, quantitative information and for electronic, as opposed to human, collection methods, as the latter are assumed to be biased and fallible.
For Sherman Kent, the founding father of CIA analysis who exerted a lasting influence on CIA analysis and was a “formative organizational leader” , truth was approached through research guided by a systematic method inspired by the hard sciences, and his influence lasted far beyond his tenure.
According to Cooper , the CIA’s “Myth of ‘Scientific Methodology’” and its “strong cultural orientation towards an ‘evidencebased’ scientism” remain deeply ingrained.
The CIA’s pervading scientism, combined with its homogeneity and insularity, distorted tasking because it precluded the Agency from understanding just how personally and emotionally Soviet Premier 16 #14179 Khrushchev, an insecure and emotional man, perceived strategic issues.
As a result, because its culture downplayed emotion in strategic issues and stressed the ‘science’ of intelligence work, the CIA failed to understand why and how Khrushchev could attempt to make a bold, strategic use of the island’s unique political and geographic situation.
This is shown in the over-confidence that arose from the apparent omniscience offered by U-2 flights , which made analysts less inclined to rely on agents’ and refugees’ reports for conclusions regarding Soviet activities and intentions.
Until the missile sites were constructed and the U2 could provide hard data as evidence, however, the CIA was unwilling to use judgment, and thus was unable to uncover Soviet intentions, by which time it was almost too late.
For practical reasons, women Cuban refugees were housed at a separate reception center in Florida.
This facility, however, had only a single, Spanish-speaking Army intelligence officer assigned to it to determine if female refugees possessed any knowledge of interest.
As Cuban refugees were arriving at the rate of 1,700 a week number offered above, a single interrogator was clearly inadequate to elicit information about events on the island from them that could have proved invaluable.
A Preference for Secrets The third relevant feature of the CIA’s culture is a preference for secrets.
Similarly, the CIA completely ignored the thousands of letters sent by Cuban to exiles in the United States that contained valuable information about the operation.
The preference also, quite naturally, led the agency to ignore several “open secrets” that, had they been considered, would likely have altered its key assumption that the Soviet would not attempt such a bold and unprecedented move as installing nuclear missiles in Cuba.
Among these open secrets was the USSR’s growing sense of encirclement and vulnerability.
Another open secret was that Khrushchev stood in awe of nuclear weapons , but knowledge of it would hardly matter in the CIA’s analytical culture of objectivity.
In short, there is generous evidence that the CIA privileged secrets and that this preference, which is a key part of the culture and identity of its members, significantly distorted the intelligence cycle.
A Drive for Consensus The fourth and final feature of the CIA’s culture and identity that emerges from the case is its continual drive for consensus.
This drive includes a process of winnowing information inside the CIA so that it neither disagrees with precedents set by the Agency’s prior positions, nor creates dismay among other agencies one of the missions of the Agency is to coordinate the 16 other United States intelligence agencies or intelligence consumers.
The existence of a clear consensus within the CIA that Cuba was not a vital interest for the Soviet Union distorted tasking as the CIA failed to ask whether the Soviets would try to make 18 #14179 strategic use of the island.
This affected tasking, minimizing the attention given to Cuba, as well as collection and analysis, as crucial information was dismissed as a result of this hypothesis.
For instance, through an informant, the CIA was able to estimate that no less than 40,000 soviet troops were present in Cuba in the spring of 1962, far more than the 15,000 previously estimated and indicative of a massive operation.
Because of the hypothesis mentioned above, no conclusion was drawn and the information was dismissed.
We also see here at work the CIA’s scientism, which leads to the neglect of human sources, and its homogeneity and insularity as the source was Cuban and hence not trusted.
As a result, the CIA feared that undertaking such data collection would embarrass the State Department and suspended the flights at a crucial time.
In effect, it blinded the agency, particularly so because as a result of its scientism and homogeneity, it had failed to develop adequate human sources or refused to trust them.
The iterative nature of the intelligence cycle reinforced initial errors in tasking, after which information filters imposed by identity and culture impeded course correction throughout the rest of the cycle.
Such corrections were unlikely to occur because the other phases of the intelligence cycle were also distorted by the same features that contributed to the initial error, creating a negative informational feedback loop, which culminates in strategic surprises.
Hence, an identity and culture-based model of strategic surprise brings what Cooper calls “the problem of the wrong puzzle” in intelligence analysis to center stage – it reveals how this problem arises, persists, and develops into a surprise.
DISCUSSION This article sought to understand how strategic surprises happen.
This research contributes to the establishment of this field of organizational research by proposing a model linking surprises to the identity and culture of the organization experiencing them.
We have suggested that by examining these features, one can understand how strategic surprises occur.
The unified understanding of the antecedent to strategic surprise provided by this model is our main contribution.
Contribution The idea of a negative informational feedback loop fueled by identity and culture that our model proposes implies that this understanding of strategic surprises is compatible with, but logically prior to prevailing explanations.
Wohlstetter identified the importance of having hypotheses to lift signals out of a confusion of noise, but she did not address in detail how these hypotheses are formed and sustained.
After a surprise, hypotheses in such an approach function as dei ex machina in that they close off further research.
An identity and culture-based model reopens the exploration of the links among surprises, the origins of the hypotheses that animate analysts, the collection systems that serve them and the dissemination of their results.
Allison and Zelikow studied political and bureaucratic culture, but in a largely positivist manner.
Therefore, their models do not provide more than a proximate understanding of why particular political questions are pursued or how specific bureaucratic idiosyncrasies repeatedly lead to surprises.
In contrast, we delve into the CIA’s identity and culture, explore those factors’ effects on the CIA’s gathering and interpretation of social facts, and then relate these elements to strategic surprises.
Similarly, while psychological explanations explain why analysts misperceive and misinterpret certain signals, they fail to answer two key questions.
In Kuhn’s terms, these models break down when summoned to explain massive paradigm shifts that are often years in the making.
In contrast, the 21 #14179 identity and culture model of surprise, which is rooted in an appreciation for social facts, addresses such failures and, as such, offers a promising avenue for future research.
However, strategic surprises should not be looked at as single events but rather as a process.
We have traced the surprise through a series of errors sustained over long periods of time at all steps of the intelligence cycle cumulating into one major erroneous assessment.
These, and not the surprise itself, constitute the crucial pathologies that our model attempts to explain.
Beyond strategic surprise itself, this paper can inform management scholars working on two specific areas.
The first is competitive strategy and, in particular, responses to competitive moves.
For instance, Zajac and Bazerman note that strategic decision makers typically do not sufficiently consider the decisions of competitors, which leads to a variety of specific judgmental mistakes, or blind spots.
Blind spots are a form of tasking failure, a look at the wrong puzzle, and typically originate from the culture and the identity of an organization, as the literature suggests.
The second area is the difficulty that incumbent firms have in responding to disruptions in their environment.
Scholars such as Christensen build on the work of Bower to show how such difficulties are often ascribed to the firm’s resources, processes, and values,e., to its identity and culture.
Our results, while largely consistent with the literature, should be confronted to a larger sample in order to mitigate the issue of contingency.
Another avenue for research would be to explore the sources of the features of identity and culture; this would help create a more complete model of strategic surprise as a social construction.
Integrating the role of identity and culture helps understand why the problem of the wrong puzzle persists, and problems are not resolved by better analytic process changes focused on signals or biases or by organizational reforms.
A model of strategic surprises as a social construction provides a unified understanding of surprise that is not in conflict with prevailing theories but logically prior to them, because the identity and culture of the organization establish the conditions under which the latter operate.
Surprise and its causes in business administration and strategic studies.
America’s Legendary Spy Master on the Fundamentals of Intelligence Gathering for a Free World.
The Ultimate Insider’s Story of Five Presidents and How They Won the Cold War.
Judgemental errors, interactive norms, and the difficulty of detecting strategic surprises.
Final Report of the National Commission on Terrorist Attacks upon the United States.
September 11 and the Adaptation Failure of United States Intelligence Agencies.
Model of strategic surprises a social construction Features of identity All steps of the and culture DISTORT intelligence process LEADS TO Strategic 1.
