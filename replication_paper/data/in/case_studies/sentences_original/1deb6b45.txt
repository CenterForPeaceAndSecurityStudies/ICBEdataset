ZEGART ^ ^ HE CUBAN MISSILE crisis marks its 50th anniversary this Ê y^^r as the most studied event of the nuclear age.
Scholars Ê and policymakers alike have been dissecting virtually W every aspect of that terrifying nuclear showdown.
Yet after half a century, we have learned the wrong intelligence lessons from the crisis.
Typically, learning is envisioned as a straight-line trajectory where time only makes things better.
Organizations (and individuals) frequently forget what they should remember and remember what they should forget.
OCTOBER C^ NOVEMBER 2012 23 Policy Review Amy B Zegart intelligence success — needs to be challenged.
Shifting the analytic lens from intelligence success to failure, moreover, reveals surprising and important organizational deficiencies at work.
Ever since Graham Allison penned Essence of Decision in 1971, a great deal of research has focused on the pitfalls of individual perception and cognition as well as organizational weaknesses in the policymaking process.
Surprisingly little work, however, has examined the crucial role of organizational weaknesses in intelligence analysis.
Many of these same problems still afflict United States intelligence agencies today.
The pre-crisis estimates of 1962 ( / HE EMPIRICAL RECORD of United States intelligence assessments leading up / to the crisis is rich.
We now know that between January and V—' October 1962, when Soviet nuclear missile sites were ultimately discovered, the CIA'S estimates offlce produced four National Intelligence Estimates and Special National Intelligence Estimates about Castro's communist regime, its relationship with the Soviet Bloc, its activities in spreading communism throughout Latin America, and potential threats to the United States.
These were not just any intelligence reports, NIES and SNIES were — and still are — the gold standard of intelligence products, the most authoritative, pooled judgments of intelligence professionals from agencies across the U.S. government.
Sherman Kent, the legendary godfather of CIA analysis who ran the CIA'S estimates offlce at the time, described the process as an ""estimating machine,"" where intelligence units in the State Department, military services, and CIA would research and write initial materials; a special CIA estimates staff would write a draft report; an interagency committee would conduct ""a painstaking"" review; and a ""full-dress"" version of the estimate would go down ""an assembly line of eight or more stations"" before being approved for dissemination.
The four pre-crisis estimates of 1962 reveal that United States intelligence officials were gravely worried about the political fallout of a hostile communist regime so close to American shores and the possibility of communist dominoes in Latin America.
But they were not especially worried about risk of a military threat from Cuba or its Soviet patron.
The flrst estimate, released January 17, 1962 , was a big-think piece that assessed threats to the United States from the Caribbean region over the next 20 years.
The time horizon is important, suggesting confidence that Khrushchev would be unwilling to risk establishing a Cuban base for at least several years.
Considering that the review period stretched 20 years into the future, this is quite a statement; the intelligence community's long-term estimate anticipated no shortor even medium-term crisis brewing.
Again, the estimate discounts heavily the possibility that estimates of Ip6z the Soviet Union would defend Cuba or establish show the U.S. offensive military capabilities there.
Carefully chosen and reviewed in the estimates process, they are meant to convey a high degree of certainty.
In fact, Khrushchev made the decision to deploy nuclear missiles to Cuba about ten weeks later, between May and June of 1962.
Massive numbers of Soviet troops were roaming about the island by fall (although total numbers were not known for the next 25 years), and nuclear missiles began arriving in early September.
The third estimate was disseminated on August i , 1962 , just a couple of weeks after intelligence began indicating a major Soviet arms buildup in Cuba.
Starting in mid-July, a stream of intelligence reporting from both technical and human sources began indicating a massive arms buildup.
This reporting increased dramatically in August and September, and the estimate's heading reflected these developments.
The estimate notes that between mid-July and early September, approximately 70 ships had delivered Soviet weaponry and construction equipment.
That number was three to four times greater than total Soviet shipments for the entire first half of 1962.
Indeed, so .concerned was President Kennedy by the new intelligence that he made explicit public warnings on September 4th and again on September 13th that if the Soviets placed offensive weapons in Cuba, ""the gravest issues would arise,"" a warning understood to imply potential nuclear confrontation.
For the fourth time in nine months, a national intelligence estimate asserted that Soviet activities in Cuba were meant to deter an American attack there and sustain a vital ideological victory for the communist cause.
Engrossed by the political threat of a strengthened communist regime in the Western hemisphere, the estimate considered but ultimately dismissed the possibility of a major offensive Soviet base.
We know now that the Soviets had, in fact, deployed nuclear missiles to East Germany briefly in 1959 and that some United States intelligence officials suspected as much before the Cuban missile crisis broke.
Yet this working group and its judgments never made it into the September 19, 1962, Cuba Special National Intelligence Estimate.
Nor did the possibility of a precedent-setting Soviet nuclear missile deployment to a satellite country appear to reach the president.
President Kennedy told his colleagues that no Soviet Eastern European satellite had nuclear weapons and that ""this would be the first time the Soviet Union had moved these weapons outside their own"" territory.
Why the East German special intelligence repon seems to have been unknown or disregarded by the estimating machine and its policymaking customers remains unclear.
More recently declassified Soviet archives reveal that the intelligence community's mistakes were not confined to misjudging Khrushchev's intentions.
It turns out that conspicuously larger numbers of Soviet military forces actually were in Cuba at the time — we just didn't know it.
Soviet forces numbered 41,900, a figure ten times higher than the September estimate, CIA estimators assumed this key indicator of a Soviet strategic missile base would be easy to see.
Instead, United States intelligence officials were unaware of the full size of the Soviet troop deployment for the next 25 years.
The intelligence success narrative DECADES, SCHOLARS and practitioners have been reluctant to the pre-crisis intelligence estimates of 1962 a strategic warning failure.
Instead, the intelligence narrative of the Cuban missile crisis has taken two contradictory forms.
One argues that intelligence warning succeeded, the other admits that no accurate warning was possible and that United States intelligence estimators did the best that anyone could.
Because the crisis ended without nuclear confrontation and gave Khrushchev a major political defeat, there is a natural tendency to conclude that the United States intelligence warning worked well.
First, although it is clear that U.S. intelligence officials discovered Soviet missiles in Cuba days before they became operational, it is equally clear that they utterly failed to anticipate the presence of Soviet missiles in Cuba every day before then.
OCTOBER & NOVEMBER 2012 27 Amy B Zegart Warning., the essence of warning is not presenting a list of iron-clad facts but anticipating and preventing the looming and murky danger of strategic surprise.
To be sure, for most of 196z, there were no nuclear missiles in Cuba to be found.
All four of the estimates had a distinctly reassuring quality to them, highlighting inferences and evidence in ways that suggested policymakers need not worry about a Soviet offensive base in Cuba.
Rather than inoculating the Kennedy administration against the horrors of a possible Soviet missile surprise in Cuba, the estimates made the surprise all the more sudden, shocking, and total.
Second, the contingency of history also cautions against finding intelligence warning success in chancy, happy outcomes.
In the case of the Cuban missile crisis, each passing decade brings new and frightening evidence of how Kennedy's ""seizing the initiative"" after seeing those U2 photographs of missile sites nearly led to nuclear disaster, not American victory.
Scott Sagan has chronicled numerous instances during the crisis where mistakes (an American U2 pilot who accidentally flew into Soviet airspace, bringing with him American Fioz-A interceptors armed with Falcon nuclear air-to-air missiles) or routine military procedures (including a previously scheduled test tape of a Soviet missile attack that ran during the crisis and was mistakenly identified as a real incoming strike) nearly spiraled out of control.
In zooz, scholars unearthed terrifying new evidence that one Soviet submarine captain actually did order preparations to launch a nuclear-tipped torpedo off the American coast.
On October Z7, bombarded by United States Navy depth charges and running out of air, the Soviet Captain gave the order to prepare a nuclear weapon for firing.
We will not disgrace our navy,"" the Soviet intelligence report quotes the Soviet captain as saying.
But in the heat of the moment, another submarine officer, Vasili Arkhipov, convinced him to await further instructions from Moscow.
The Soviets mounted a substantial denial and deception program to keep the deployment secret.
The second variant of the success narrative maintains that United States intelligence estimators may have been wrong, but they did the best that anyone could.
In this particular case, Kent admits to being dead wrong but then claims no one could possibly have predicted Khrushchev's irrational behavior.
With a few exceptions, examinations of the Cuban missile crisis have picked up this theme.
Blaming the adversary for his unpredictable behavior is an odd argument, to say the least.
By this measure, the Cuban missile crisis seems a textbook case of anomaly leading to crisis.
Nor had they ever provided such an extraordinary level of military aid to Cuba.
But starting in the spring of 1962, ships were sailing, and by summer, crates of weapons — lots of them — were being unloaded.
Something different was definitely afoot, and United States intelligence officials knew it.
Yet their estimates confronted these anomalies and declared them more of the same.
The benefits of calling a failure a failure ^ _^ALLiNG SOMETHING A success Or failure is not simply an exercise in I semantics.
Seeking to explain ""why warnOcTOBER & NOVEMBER 2012 29 Amy B Zegart ing was so hard,"" intelligence research on the crisis has focused primarily on cognitive psychology and the pitfalls inherent in human cognition.
Organizational explanations, by contrast, have remained an under-tilled area.
While much has been made of bureaucratic politics in presidential decision-making, little has been done to examine the silent but deadly role of organizational weaknesses in intelligence during the Cuban missile crisis.
But more recent analyses of the September 11 terrorist attacks and the faulty estimates of Iraq's weapons of mass destruction suggest that organizational weaknesses in intelligence can have devastating effects.
And regarding the Cuban missile crisis, there are lingering questions surrounding such weaknesses.
I Signals and noise have been a major part of every intelligence post-mortem since Pearl Harbor. silent Roberta Wohlstetter, who coined the terms, organizational observed that intelligence warning requires analysts to separate ""signals,"" or clues that point to an adverStructures and sary's future action, from a background that is filled processes that ^^^ ""noise,"" or intelligence indicators that turn out J . to be irrelevant, confusing, or just plain wrong.
Wohlstetter's important insight warns against the perils of hindsight bias.
But it has also generated analytic pathologies of its own, focusing our sites more on the ratio of signals to noise and the analytic techniques to improve individual perception than the organizational forces that cause signals to get noticed or missed.
Rarely, however, do we examine the silent organizational structures and processes that determine whether signals get noticed or ignored, amplified or dispersed.
A brief comparison of the Cuban missile crisis and the September 11 terrorist attacks illustrates the point.
Immediately after the Cuban missile crisis, the steady refrain was that intelligence noise was tremendous while signals were scarce, CIA Director John McCone wrote that his agency received 7.
According to the President's Foreign Intelligence Advisory Board, just 3 5 of these reports turned out to be signals indicating the actual Soviet deployment.
McCone, Kent, Wohlstetter, Garthoff, and others argue forcefully that these were terrible odds for detecting signals of Khrushchev's nuclear gambit.
Intelligence officials working in the weeks and warning problem months before the September 11 terrorist attacks isn't the number would gladly have traded signals-to-noise ratios with their Cuban missile crisis counterparts.
In 1962, 0/ Signals out the there were just 5,000 computers worldwide, no fax organizational machines, and no cell phones.
The collec° ° tion backlogs at NSA alone were so enormous that less than i percent of the intake was ever decoded or processed.
Against this astounding noise level, signal detection remained about the same as it was in 1962.
I found that in the two years before 9/11, United States intelligence officials picked up a grand total of 23 signals that al-Qaeda was planning a major attack on the United States homeland.
As the comparison suggests, quantifying signals and noise tells part of the warning story, but not the most important part.
Instead, the crucial problem had to do with organizational deficiencies that ensured every signal, once detected, would eventually get lost in the bureaucracy.
Chief among these organizational deficiencies was structural fragmentation — jurisdictional divisions within and across intelligence agencies that dispersed and isolated signals in different places.
Seven weeks before 9/11, for example, three of the FBI'S 56 United States field offices independently uncovered what turned out to be three key signals.
In Phoenix, Special Agent Kenneth Williams identified a pattern of jihadists 8.
O C T O B E R & N O V E M B E R 2012 31 Amy B Zegart attending United States flight schools and wrote a memo urging that flight schools be contacted, specific individuals be investigated, and other intelligence agencies, including the CIA, be notified.
In Minneapolis, FBI agents arrested Zacarias Moussaoui, a suspicious extremist who wanted tofly747s and paid $6,000 in cash to use a flight simulator but lacked all of the usual credentials.
He became the only person convicted in the United States for his connection to the attacks.
Yet because the FBI field office structure was highly decentralized, none of the agents working these cases knew about the othTt i<; thp ra<ip ^^^' ^^ because a gaping divide separated domestic and foreign intelligence agencies, the CIA and the that in 1^62., rest of the United States intelligence community never seized iust as in 2001 these or other FBI leads in time, either.
Minneapolis agents tried to obtain a search warrant Agency was <• r m • 1 • r o y — unaware of the Phoenix memo or the existence of central in another terrorist in FBI custody who could have Ï identified Moussaoui from al-Qaeda's training ^' camps.
An FBI agent went searching blindly for alM i h d h a r and al-Hazmi in N e w York hotels, unaware that the Bureau's San Diego field office had an informant who knew both terrorists.
In these cases, and 20 others, someone somewhere in the intelligence bureaucracy noticed something important.
They were found, and then subsequently lost in the bowels of the bureaucracy.
Even a cursory look at the Cuban missile crisis suggests that structural fragmentation appears to have played a similar role then, isolating and weakening signals rather than concentrating and amplifying them.
In 1962, just as in 2001, the Central Intelligence Agency was central in name only.
Created just fifteen years earlier, the CIA had been hobbled from birth by existing intelligence agencies in the State, Justice, War, and Navy Departments, all of which vigorously protected their own missions, budgets, and power.
The CIA, in fact, did not control the intelligence budgets or activities of the Defense Intelligence Agency, the National Security Agency, or any of the military intelligence services, all of which reported to the secretary of defense.
What's more, the Bay of Pigs debacle of April 1961 made a weak CIA even weaker.
John McCone, a Republican businessman with staunch anticommunist leanings and no professional intelligence experience.
The Defense Intelligence Agency photographed deck cargoes of Soviet ships en route from the Soviet Union.
The Navy conducted air reconnaissance of ships entering and leaving Cuba.
The CIA ran human agents in Cuba, but jointly operated a special Cuban refugee debriefing center in Florida with the military.
The National Security Agency intercepted communications indicating Soviet ship movements, radio transmissions in Cuba, and other signals intelligence.
At first the CIA, and then the Strategic Air Command, manned uz Intelligence reconnaissance flights over Cuba.
Estimates, finally, ti f' // were technically produced by the CIA'S Office of r 6 National Estimates but coordinated and approved analysis of the by an interagency group called the United States Intelligence Cuban situation Board.
In short, in 196z, as in zooi, there were many bureaucratic players and no one firmly in U>as handled by charge of them all. half a dozen Although a more thorough organizational analyj . , ^ sis of how every signal was processed through the different bureaucracy lies beyond the scope of this essay, iniagencies. tial evidence does suggest that organizational fragmentation existed, and that it had the effect of delaying action and hindering signal consolidation.
For example, retrospective examinations by both the CIA and the President's Foreign Intelligence Advisory Board found that there was ""rigid compartmentation"" between aerial imagery collectors and CIA analysts and that this structural divide kept the CIA from disseminating reports and information about the possibility of offensive Soviet weapons in Cuba before the October 14th discovery of missile installations.
The PFIAB report on the crisis, which was completed in February 1963, finds that before October 14, CIA analysts did not publish any information indicating a potential offensive buildup in Cuba in the president's daily intelligence checklist, the most important current intelligence product.
The agency's rules required that any report that could be verified by photographic evidence first had to be sent to the National Photographic Interpretation Center , a separate CIA unit located in the Directorate of Science and Technology.
For CIA analysts housed inside the agency's Directorate of Intelligence, this was the bureaucratic equivalent of Lower Slobovia.
What's more, there was no systematic process to inform analysts about the status of their aerial verification requests to NPIC, SO requests could languish or simply disappear without any further action.
Without any idea whether further action would ever be taken, analysts simply withheld information from their written products.
The PFIAB found that analysts misOcTOBER & NOVEMBER 2012 33 Amy B Zegart takenly interpreted the verification rule as an outright ban on publishing all reports of offensive Soviet weapons without definitive photographic proof.
This same rigid bureaucratic division between analysis and photographic collection created a filter that appears to have hindered initial signal detection as well.
According to the PFIAB chronology, a September 9th report from Castro's personal pilot claimed that there were ""many mobile ramps for intermediate range rockets,"" an item subsequently deemed significant.
At the time, however, it was given only ""routine"" precedence because the CIA analyst who saw it was charged with identifying information relevant for aerial surveillance, and thought the information was ""too general"" to be of targeting use.
In short, preliminary evidence suggests that the Preliminary same organizational barriers operating on 9/11 were also at work during the missile crisis.
Indeed, given evidence suggests ^]^Q jQj^g ^j^j sordid history of intelligence coordinathat the same ^oi^ problems, it seems unlikely that Cuban intelli, gence reporting constituted a shining exception ° where intelligence warning signals were collected, barriers operating assessed, and disseminated by a well-oiled coordinann O/TT t/jprp ^^^^ machine.
Instead, in both cases, bureaucratic jurisdictions and standard operating procedures also at work ended up creating invisible fault lines within and during the across intelligence agencies that kept signals from converging.
Structural fragmentation made it likely missile crisis. ^j^^j. signals would get lost, even after they had been found.
Recall that the estimate clearly indicated conditions on the ground had changed since the previous estimate, which was published on August i , 1962.
This report structure had the effect of sharply distinguishing present intelligence reporting about the military buildup from speculation about future possibilities.
According to the estimate, intelligence about the buildup clearly showed the Soviets adopting a defensive posture, just as earlier assessments had concluded.
In other words, earlier judgments about Soviet objectives and intentions still held.
In the immediate aftermath of the crisis, Kent took a great deal of criticism for the September 19th estimate.
Nearly all of it centered on analytic misjudgments, particularly mirror imaging or the tendency for analysts to believe an adversary will behave as they would.
And as noted above, more recent scholarly work also focuses on problems of perception and cognition.
According to this work, American estimators failed to see the world or weigh the costs and benefits of the missile deployment through Soviet eyes.
But mirror imaging was not the only problem hindering the estimates process.
Organizational pressures were also driving strongly toward conformity and consistency across the four Cuba estimates.
These reports were OCTOBER & NOVEMBER 2012 35 Amy B Zegart not the product of a single mind, a single view, or even a single agency.
They were collective reports that required interagency coordination and consensus.
And that organizational fact of life tilted the whole estimating machine toward consistency over time.
Presidential advisors did not need to be convinced that the world essentially looked the same today as it did last month.
Where consistency was a given, inconsistency had to be explained, justified, and defended.
Changing a previous estimate required taking a fresh look, marshaling both new and old facts, and laying out what had shifted, and why.
That, in turn, meant overcoming immense bureaucratic inertia — convincing every intelligence Changing a agency involved in the estimating process that what it said or assessed or wrote or agreed to the last previous estimate time should be discarded or modified this time. required taking Changing an earlier estimate did not just take more rill work inside each agency.
In out what had short, organizational dynamics naturally gave consistency the upper hand.
By political considerations, I do not mean to suggest that estimators bent their judgments to curry favor or told policymakers what they wanted to hear.
Instead, my point is that switching course on an analytic judgment is always harder when the political stakes for the country and the administration are known to be high.
In these situations, any new estimate that revises earlier judgments can be seized, however unjustifiably, as proof that earlier estimates were wrong.
The Cold War stakes had never been greater and the CIA had already caused Kennedy a devastating defeat in the Bay of Pigs invasion just eighteen months earlier.
Now, with midterm congressional elections just weeks away, the pressure to ""get Cuba right"" was tremendous.
In this environment, an intelligence estimate that gave serious consideration to a new, more ominous reading of the Soviet buildup would almost certainly have been read as an indictment of earlier, less alarming estimates.
And it would have contradicted earlier public assurances by the president himself, as well as his closest advisors, that the Soviet buildup was purely defensive in nature.
Such considerations may not have been in the foreground of the estimates process, but it is hard to imagine that they were not in the background.
The above discussion helps illuminate why the estimates were consistent even when confronting dramatically new facts.
It does not, however, explain why the estimates failed to contain any dissenting views.
As noted earlier, footnotes were used to provide dissenting opinions in estimates of other subjects written during the same period.
As Wohlstetter writes, ""let us remember that the intelligence community was not alone.
It had plenty of support from Soviet experts, inside and outside the Government.
CIA Director estimates contain John McCone, who suspected Soviet missiles from ,. the start.
McCone was a paranoid anticommunist "" ^ ^ ^ ^ "" "" ^ ^ Vtews, who always seemed to find signs of aggressive Soviet and where were behavior, and was often wrong.
In fact, the historical footnotes in the record shows that he forcefully advocated his TQ6Z estintates^ hypothesis about Soviet missiles with senior Kennedy advisors on several occasions, starting in August 1962.
And after SAM sites were discovered, he sent a series of cables to Washington from his European honeymoon, again strenuously asserting his hypothesis (the SAM sites, he beheved, had to be guarding something important) and requesting additional reconnaissance.
The question, then, is why he never did so in the national intelligence estimates.
Some argue that McCone refrained from foisting his opinions or judgments on the estimates process, and conclude that this was a good thing.
Briefly put, the notion is that all organizations specialize to increase efficiency, and specialization turns out to be a double-edged sword.
OCTOBER & NOVEMBER 2012 37 Amy B Zegart labor into subunits enables experts to tackle specialized tasks in specialized ways.
On the other hand, however, specialization generates organizational structures and standard operating procedures that filter out information and keep an organization from learning.
Standard ways of writing reports, assembly line production processes, and rigid communication channels — all of these things help managers work across sub-units efficiently.
But they also keep ideas that do not fit into the normal formats and channels from getting heard.
Reports, for example, are written in certain ways, with certain types of information, for certain purposes, and certain audiences.
This setup is designed to create a standard product precisely by weeding out nonstandard ideas and approaches.
Organizations are filled with these kinds of standard formats and operating procedures.
The trouble is FiftV vears ^^^^ ^^^ more that things get done the same way each time, the harder it is to do things differently. after the Cuban The entire system becomes a well-oiled machine missile crisis ^^^^^ ^^ ^^^ ^^""-y existence, keeps alternative ideas or ... ways of operating from getting through. intelligence information that could be valuable to the organizawarning is still tio^^ remains hidden.
It was challenges highly specialized, with multiple units, offices, and agencies collecting and analyzing different pieces of the Cuba intelligence puzzle.
Kent himself describes the estimates process as a ""machine,"" with specific stations, regularized processes, and an ""assembly line"" production.
Notably, one of the key features of the estimating machine was its evidentiary standard for revising earlier estimates or voicing dissenting views.
Kent writes extensively about what it would have taken to revise the September 19 th estimate or offer a dramatically different, stronger view of the buildup and concludes that the evidence was simply not there.
The same was true of footnotes, which were ordinarily used for airing disagreements about evidence.
The CIA director's approach never fit into this standard operating procedure.
And there was no place in the National Intelligence Estimates or Special National Intelligence Estimates for such things.
And while he waited for the estimating gears to grind, he made his case — in meeting after meeting, cable after cable — to Kennedy and his top advisors.
Structural secrecy led the estimating machine to run smoothly into failure.
Lessons for today C yiFTY YEARS AFTER the Cuban missile crisis, intelligence warning is ^y'still plagued by many of the same challenges.
And yet, some of the most powerful barriers to effective intelligence warning remain relatively unexplored.
Organizations are not passive players, where individuals do all of the hard thinking and make all of the tough calls.
Instead, organizations powerfully influence whether signals get amplified or weakened, whether analysis looks backward at continuity or leans forward toward disjuncture, and whether dissent gets highlighted or hidden.
