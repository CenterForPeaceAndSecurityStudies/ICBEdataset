---
title: "Untitled"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown


Pull specific examples

```{r, eval=F}

rex_paste <- function(x) { x %>% unique() %>% na.omit() %>% paste0(sep=";", collapse=";")}
rex_count <- function(x) { x %>% unique() %>% na.omit() %>% paste0(sep=";", collapse=";")}
sentence_variable_widecoder_Event_Any <-icb_long_clean  %>% 
  dplyr::select(email_id,crisno,sentence_number_int_aligned, section, sentence, event_number_int, variable_normalized, value_normalized) %>% 
  dplyr::filter(variable_normalized=='Event_Any') %>%
  dplyr::filter(value_normalized!='' & !is.na(value_normalized)) %>%
  dplyr::select(-variable_normalized, -event_number_int) %>%
  group_by(crisno,sentence_number_int_aligned) %>%
    mutate(coders=email_id %>% unique() %>% length()) %>%
    mutate(answers_unique=value_normalized %>% unique() %>% length()) %>%
    mutate(answer_modal= value_normalized %>% table() %>% sort() %>% rev() %>% .[1]) %>%
  ungroup() %>%
  mutate(answer_modal_perc= round( answer_modal/coders,2 )) %>%
  pivot_wider(id_cols=c(crisno,sentence_number_int_aligned, section, sentence,coders,answers_unique,answer_modal,answer_modal_perc), names_from=email_id,values_from=value_normalized, values_fn=rex_paste) %>%
  arrange(crisno,sentence_number_int_aligned)


#sentence_variable_widecoder %>%   View()

hist(sentence_variable_widecoder$answer_modal_perc)
table(sentence_variable_widecoder$answer_modal_perc)

```

```{r}


```



```{r, eval=F}

rex_paste <- function(x) { x %>% na.omit() %>% sort() %>% paste0(sep=";", collapse=";") %>% str_replace_all(";;",";")  } #
rex_count <- function(x) { x %>% unique() %>% na.omit() %>% sort() %>% paste0(sep=";", collapse=";")  %>% str_replace_all(";;",";") } #

rex_count <- function(x) { x %>% na.omit() %>% table() %>% sort() %>% rev() %>% .[1] } #

temp2 <-icb_long_clean  %>% 
  dplyr::select(email_id,crisno,sentence_number_int_aligned, section, sentence, event_number_int, variable_normalized, value_normalized) %>% 
  #dplyr::filter(variable_normalized=='Event_Any') %>%
  dplyr::filter(value_normalized!='' & !is.na(value_normalized)) %>%
  dplyr::select(-event_number_int) %>%
  group_by(email_id, crisno,sentence_number_int_aligned, section, sentence,variable_normalized) %>%
    summarise(value_normalized=value_normalized %>% rex_paste() )

a <- icb_long_clean %>% filter(sentence %>% str_detect("And when Ethiopia perceived war as imminen")) 
a <- icb_long_clean %>% filter(crisno==47 & sentence_number_int_aligned==40) 
a %>% View()

b <- a %>% 
  dplyr::select(email_id,crisno,sentence_number_int_aligned, section, sentence, event_number_int, variable_normalized, value_normalized) %>% 
  #dplyr::filter(variable_normalized=='Event_Any') %>%
  dplyr::filter(value_normalized!='' & !is.na(value_normalized)) %>%
  dplyr::select(-event_number_int) %>%
  group_by(email_id, crisno,sentence_number_int_aligned, section, sentence,variable_normalized) %>%
    summarise(value_normalized=value_normalized %>% rex_paste() ) %>%
  group_by(crisno,sentence_number_int_aligned) %>%
    mutate(coders=email_id %>% unique() %>% length()) %>%
  ungroup() %>%
  group_by(crisno,sentence_number_int_aligned,variable_normalized) %>%
    mutate(coders=email_id %>% unique() %>% length()) %>%
    mutate(answers_unique=value_normalized %>% na.omit() %>% unique() %>% length()) %>%
    mutate(answer_modal= value_normalized %>% na.omit() %>% table() %>% sort() %>% rev() %>% .[1] ) %>%
    mutate(answer_modal_perc= round( answer_modal/coders,2 )) %>%
  ungroup() %>%
  pivot_wider(id_cols=c(crisno,sentence_number_int_aligned, section, sentence,variable_normalized,coders,answers_unique,answer_modal,answer_modal_perc), names_from=email_id,values_from=value_normalized, values_fn=rex_paste) %>%
  arrange(crisno,sentence_number_int_aligned,variable_normalized)



```


```{r}



icb_long_clean  %>% 
  dplyr::select(email_id,crisno,sentence_number_int_aligned, section, sentence, event_number_int, variable_normalized, value_normalized) %>% 
  dplyr::filter(variable_normalized=='sentence_events') %>%
  dplyr::select(-variable_normalized, -event_number_int) %>%
  pivot_wider(id_cols=c(crisno,sentence_number_int_aligned, section, sentence), names_from=email_id,values_from=value_normalized, values_fn=rex_paste) %>%
  arrange(crisno,sentence_number_int_aligned) %>%
  View()


temp <-icb_long_clean  %>% 
  dplyr::select(email_id,crisno,sentence_number_int_aligned, section, sentence, event_number_int, variable_normalized, value_normalized) %>% 
  dplyr::filter(variable_normalized=='Event_Count') %>%
  dplyr::filter(value_normalized!='' & !is.na(value_normalized)) %>%
  dplyr::select(-variable_normalized, -event_number_int) %>%
  group_by(crisno,sentence_number_int_aligned) %>%
    mutate(coders=email_id %>% unique() %>% length()) %>%
    mutate(answers_unique=value_normalized %>% unique() %>% length()) %>%
    mutate(answer_modal= value_normalized %>% table() %>% sort() %>% rev() %>% .[1]) %>%
  ungroup() %>%
  mutate(answer_modal_perc= round( answer_modal/coders,2 )) %>%
  pivot_wider(id_cols=c(crisno,sentence_number_int_aligned, section, sentence,coders,answers_unique,answer_modal,answer_modal_perc), names_from=email_id,values_from=value_normalized, values_fn=rex_paste) %>%
  arrange(crisno,sentence_number_int_aligned)

temp %>%   View()

hist(temp$answer_modal_perc)




```



Experimenting with flattening strategies

```{r}

#icb_long_clean %>%  filter(variable %>% str_detect('date')) %>%  pull(value) %>% tolower() %>% trimws() %>% unique() %>% length()  #9667
#icb_long_clean %>% filter(variable %>% str_detect('actor')) %>% pull(value) %>% tolower() %>% trimws() %>% unique() %>% length()  #2090
#icb_long_clean %>% filter(variable %>% str_detect('location')) %>% pull(value) %>% tolower() %>% trimws() %>% unique() %>% length()  #3766

icb_long_clean %>%   filter(!variable %>% str_detect('date|actor|location|sentence|reorder|react')) %>% dplyr::select(variable_normalized,value_normalized) %>% distinct() %>% nrow()  #3766


icb_long_clean %>% 
  filter(!variable %>% str_detect('date|actor|location|sentence|reorder|react|coder_crisis_order|preceding_event|time|condition_|raterconfidence_reason_survey|raterconfidence')) %>% 
  mutate(value=value %>% tolower()) %>% 
  dplyr::count(variable,value) %>%
  filter(n>1) #%>%  View() #About 270 unique values that show up more than once


icb_long_clean %>% 
  filter(variable %>% str_detect('actor')) %>% 
  mutate(value=value %>% tolower()) %>% 
  dplyr::count(variable,value) %>%
  filter(n>1) #%>%  View() #About 270 unique values that show up more than once


coder_sentence_event_dummy <-
          icb_long_clean %>% 
          dplyr::rename(variable =variable_normalized,value =value_normalized) %>%
          filter(!variable %>% str_detect('date|actor|location|think_sentence_events|reorder|react|coder_crisis_order|preceding_event|time|condition_|raterconfidence_reason_survey|raterconfidence')) %>% 
          mutate(value=value %>% tolower()) %>%
          dplyr::select(email_id,crisno,sentence_number_int_aligned,event_number_int, variable, value) %>% 
          mutate(variable=variable %>% str_replace('_other','')) %>% #make sure we kill others, don't care if it's an other
          distinct() %>%
          mutate(var_value=paste(variable,value,sep=";")) %>%
          fastDummies::dummy_cols(select_columns='var_value', remove_selected_columns=T) %>%
          dplyr::select(-variable, -value, -event_number_int) %>%
          group_by(crisno,sentence_number_int_aligned, email_id) %>%
            summarise_all(max, na.rm=T) 
dim(coder_sentence_event_dummy) #16031   252 other values
names(coder_sentence_event_dummy) <- names(coder_sentence_event_dummy) %>% str_replace('var_value_','')
names(coder_sentence_event_dummy)

#coder_sentence_event_dummy %>% dplyr::select(email_id,crisno,sentence_number_int_aligned, contains("event_type")) %>% View()
#coder_sentence_event_dummy %>% dplyr::select(email_id,crisno,sentence_number_int_aligned, contains("sentence_events")) %>% View()

coder_sentence_event_dummy_sentence <- coder_sentence_event_dummy %>% 
                                        dplyr::select(-email_id) %>%
                                        group_by(crisno,sentence_number_int_aligned) %>%
                                          mutate(coders=1) %>%
                                          summarise_all(sum, na.rm=T) %>%
                                        pivot_longer(cols=c(-crisno,-sentence_number_int_aligned)) %>%
                                        filter(value>0) %>%
                                        group_by(crisno,sentence_number_int_aligned) %>%
                                          mutate(coders=ifelse(name=="coders", value, NA)) %>%
                                          mutate(value=(value-1)/ (max(coders, na.rm=T)-1) ) %>%
                                        ungroup()  %>%
                                        mutate(value_count=1) %>%
                                        group_by(name) %>%
                                          mutate(value_count = value_count %>% sum() ) %>%
                                        ungroup()  %>%
                                        filter(name!='coders') %>%
                                        filter(value_count>1)
table(coder_sentence_event_dummy_sentence$value)
summary(coder_sentence_event_dummy_sentence$value)

coder_sentence_event_dummy_sentence %>% dplyr::select(name, value_count) %>% distinct() %>% View()

coder_sentence_event_dummy_sentence %>%
  group_by(name) %>%
  summarise(value_mean=mean(value, na.rm=T)) %>% View()

coder_sentence_event_dummy_sentence %>%
  group_by(name) %>%
  summarise(value_mean=mean(value, na.rm=T)) %>% pull(value_mean) %>% summary()

coder_sentence_event_dummy_sentence %>% 
  separate(name, c("A", "B"), sep=";") %>%
  group_by(A) %>%
  summarise(value_mean=mean(value, na.rm=T)) %>% View()

actor_keep <- icb_long_clean %>% 
                dplyr::select(-variable,-value) %>% dplyr::rename(variable =variable_normalized,value =value_normalized) %>%
                filter(variable %>% str_detect('actor')) %>% 
                filter(!variable %in% non_clean_versions) %>%
                mutate(value=value %>% tolower()) %>% 
                dplyr::count(value) %>%
                filter(n>1) %>% 
                na.omit() %>%
                mutate(value=value %>% str_replace('https://en.wikipedia.org/wiki/','')) %>%
                filter(!value %in% c("no_cleaning", "drop"))
                #View() #About 395

coder_sentence_event_actor_dummy <-
          icb_long_clean %>% 
          dplyr::select(-variable,-value) %>%
          dplyr::rename(variable =variable_normalized,value =value_normalized) %>%
          filter(variable %>% str_detect('actor|sentence_events')) %>% 
          filter(!variable %in% non_clean_versions)  %>%
          mutate(value=value %>% tolower()) %>%
          mutate(value=value %>% str_replace('https://en.wikipedia.org/wiki/','')) %>%
          filter(value %in% c(actor_keep$value) | event_number_int=='0' ) #I think as long as we add event_number_int then we get a row for every coder including who said no events

#Whether the actor is mentioned at all
c <- coder_sentence_event_actor_dummy %>% 
      dplyr::select(email_id,crisno,sentence_number_int_aligned,event_number_int, variable, value) %>% 
      mutate(variable=variable %>% str_replace('_clean','')) %>%
      mutate(variable=variable %>% str_replace('_other','')) %>% #make sure we kill others, don't care if it's an other
      mutate(variable=variable %>% str_replace('_a$|_b$','')) %>%
      mutate(variable=variable %>% str_replace('^do_|^say_|condition_do_|think_','')) %>%
      distinct() %>%
      mutate(var_value=paste(variable,value,sep=";")) %>%
      fastDummies::dummy_cols(select_columns='var_value', remove_selected_columns=T) %>%
      dplyr::select(-variable, -value, -event_number_int) %>%
      group_by(crisno,sentence_number_int_aligned, email_id) %>%
        summarise_all(max, na.rm=T) 
names(c) <- names(c) %>% str_replace('var_value_','')
dim(c) #26789 336

c_sentence <- c %>% 
              #dplyr::select(-email_id) %>%
              group_by(crisno,sentence_number_int_aligned) %>%
              summarise_all(mean, na.rm=T) %>%
              pivot_longer(cols=c(-crisno,-sentence_number_int_aligned)) %>%
              filter(value>0) %>%
              filter(!name %>% str_detect('sentence_events'))

#Actors by type ignoring direction
b <- coder_sentence_event_actor_dummy %>% 
      dplyr::select(email_id,crisno,sentence_number_int_aligned,event_number_int, variable, value) %>% 
      mutate(variable=variable %>% str_replace('_clean','')) %>%
      mutate(variable=variable %>% str_replace('_other','')) %>% #make sure we kill others, don't care if it's an other
      mutate(variable=variable %>% str_replace('_a$|_b$','')) %>% 
      distinct() %>%
      mutate(var_value=paste(variable,value,sep=";")) %>%
      fastDummies::dummy_cols(select_columns='var_value', remove_selected_columns=T) %>%
      dplyr::select(-variable, -value, -event_number_int) %>%
      group_by(crisno,sentence_number_int_aligned, email_id) %>%
        summarise_all(max, na.rm=T) 
names(b) <- names(b) %>% str_replace('var_value_','')

b_sentence <- b %>% 
              #dplyr::select(-email_id) %>%
              group_by(crisno,sentence_number_int_aligned) %>%
                summarise_all(mean, na.rm=T) %>%
              pivot_longer(cols=c(-crisno,-sentence_number_int_aligned)) %>%
              filter(value>0) %>%
              filter(!name %>% str_detect('sentence_events'))
summary(b_sentence$value)
dim(b) #26789   918

#Actors by type and direction
a <- coder_sentence_event_actor_dummy %>% 
      dplyr::select(email_id,crisno,sentence_number_int_aligned,event_number_int, variable, value) %>% 
      mutate(variable=variable %>% str_replace('_clean','')) %>%
      mutate(variable=variable %>% str_replace('_other','')) %>% #make sure we kill others, don't care if it's an other
      distinct() %>%
      mutate(var_value=paste(variable,value,sep=";")) %>%
      fastDummies::dummy_cols(select_columns='var_value', remove_selected_columns=T) %>%
      dplyr::select(-variable, -value, -event_number_int) %>%
      group_by(crisno,sentence_number_int_aligned, email_id) %>%
        summarise_all(max, na.rm=T) 
names(a) <- names(a) %>% str_replace('var_value_','')
dim(a) #26789  1454

a_sentence <- a %>% 
              #dplyr::select(-email_id) %>%
              group_by(crisno,sentence_number_int_aligned) %>%
                summarise_all(mean, na.rm=T) %>%
              pivot_longer(cols=c(-crisno,-sentence_number_int_aligned)) %>%
              filter(value>0) %>%
              filter(!name %>% str_detect('sentence_events'))
summary(a_sentence$value)





#I Think what this means is that multiply these probabilities and it helps to 


```



```{r}

library(dplyr, warn.conflicts = FALSE)
options(warn=-1)

icb_long_clean$email_id_expert <- icb_long_clean$email_id %>% str_detect("grad|postgrad")

#icb_long_clean %>% dplyr::select(variable) %>% distinct() %>% View()

paste_collapse=function(x) paste(x %>% sort(), collapse=";") %>% str_replace_all("https://en.wikipedia.org/wiki/",'') #sorting removes the order indeterminacy
actors_clean <- icb_long_clean %>%
                filter(variable %>% str_detect('actor') & variable %>% str_detect('clean')) %>%
                mutate(variable=variable %>%str_replace('other_','')) %>% #removing the text other from the variable will auto include it in our list here
                pivot_wider(names_from=variable,
                            values_from=value,
                            values_fn=paste_collapse
                            ) %>%
                 dplyr::mutate(think_actor_a_clean = strsplit(as.character(think_actor_a_clean), ";")) %>% tidyr::unnest(think_actor_a_clean) %>% dplyr::mutate(think_actor_a_clean=think_actor_a_clean %>% trimws()) %>%
                 dplyr::mutate(say_actor_a_clean = strsplit(as.character(say_actor_a_clean), ";")) %>% tidyr::unnest(say_actor_a_clean) %>% dplyr::mutate(say_actor_a_clean=say_actor_a_clean %>% trimws()) %>%
                 dplyr::mutate(say_actor_b_clean = strsplit(as.character(say_actor_b_clean), ";")) %>% tidyr::unnest(say_actor_b_clean) %>% dplyr::mutate(say_actor_b_clean=say_actor_b_clean %>% trimws()) %>%
                 dplyr::mutate(do_actor_a_clean = strsplit(as.character(do_actor_a_clean), ";")) %>% tidyr::unnest(do_actor_a_clean) %>% dplyr::mutate(do_actor_a_clean=do_actor_a_clean %>% trimws()) %>%
                 dplyr::mutate(do_actor_b_clean = strsplit(as.character(do_actor_b_clean), ";")) %>% tidyr::unnest(do_actor_b_clean) %>% dplyr::mutate(do_actor_b_clean=do_actor_b_clean %>% trimws()) 
                  #currently ignoring condition
dim(actors_clean)


#I think we convert this to actor-event, where every lhs actor mentioned gets a row and then we ask what people thought THEY did in that sentence
temp_long <- icb_long_clean %>%
             filter(!variable %>% str_detect('actor') ) %>%
            dplyr::select(icb_survey_version, email_id,  crisno, sentence_number_int_aligned, section, event_number_int,  variable, value) %>%
            filter(variable %in% c(
                                   'sentence_events',
                                   'act_cooperative',
                                   'act_descalate', 
                                   'act_escalate',
                                   'act_uncooperative',
                                   'interact_decreasecoop',
                                   'interact_descalate',
                                   'interact_escalate',
                                   'interact_increasecoop',
                                   'thinkkind',
                                   'sayintkind'
                                   ) 
                        ) %>% distinct() %>% 
                  mutate(value= value %>% trimws() %>% tolower()) %>%
                  #left_join(full_tree %>% dplyr::select(Behavior, value=Leaf) %>% 
                  #            mutate(value= value %>% trimws() %>% tolower())) %>%
                  left_join(full_tree %>% dplyr::rename(value=Leaf)  %>%
                              mutate(value= value %>% trimws() %>% tolower()) ) %>%
              group_by(email_id,  crisno, sentence_number_int_aligned) %>%
                mutate(event_number_int_max=max(event_number_int, na.rm=T)) %>%
              ungroup() %>%
              full_join(
                actors_clean %>% dplyr::select(email_id,  crisno, sentence_number_int_aligned,  event_number_int,  contains('actor')) %>%
                  dplyr::select(-condition_do_actor_a_clean,-condition_do_actor_b_clean) #ignoring conditions for now
              )


#temp_long %>% dplyr::select(value, Behavior) %>% distinct() %>% View()

#i_think_actor_a=, #we're going to join on these
#i_say_actor_a=,
#i_say_actor_b=,
#i_do_actor_a=,
#i_do_actor_b=,

#Starting first with the 63% of the time they saw only 1 event
events_variable_value <- temp_long %>%
                                #filter(!is.na(Behavior )) %>%
                                #filter(event_number_int_max==1) %>%
  
                                mutate(index=paste(crisno , sentence_number_int_aligned ,  think_actor_a_clean,say_actor_a_clean,say_actor_b_clean,do_actor_a_clean,do_actor_b_clean, sep="_")) %>% #add actors to this
                                #filter(!index %>% str_detect('_NA_NA_NA_NA_NA')) %>% #ignore 
                                dplyr::select(icb_survey_version,
                                              email_id,
                                              index, 
                                              crisno,
                                              sentence_number_int_aligned,
                                              section,
                                              #contains('actor'),
                                              Event_Count,
                                              Behavior,
                                              think_aggression,
                                              say_aggression,
                                              do_aggression,
                                              Do_Armed_Unarmed,
                                              do_Act_Interact,
                                              Think_Type_L0,
                                              Say_Type_L0,
                                              Do_Type_L0,
                                              Leaf_Simplified#,
                                              #variable,
                                              #value
                                              )


                                              
#This actually takes a while now that there are dead
library(fastDummies)
#I think we do physically have to go to wide
events_wide_i <- events_variable_value %>% 
                                       rename(i_email_id=email_id,
                                              i_Event_Count=Event_Count,
                                              i_Behavior=Behavior,
                                              i_think_aggression=think_aggression,
                                              i_say_aggression=say_aggression,
                                              i_do_aggression=do_aggression,
                                              i_Do_Armed_Unarmed=Do_Armed_Unarmed,
                                              i_do_Act_Interact=do_Act_Interact,
                                              i_Think_Type_L0=Think_Type_L0,
                                              i_Say_Type_L0=Say_Type_L0,
                                              i_Do_Type_L0=Do_Type_L0,
                                              i_Leaf_Simplified=Leaf_Simplified
                                              ) %>%
                                       fastDummies::dummy_cols(select_columns='i_Event_Count', remove_selected_columns=T) %>%
                                       fastDummies::dummy_cols(select_columns='i_Behavior', remove_selected_columns=T, ignore_na = T) %>%
                                       fastDummies::dummy_cols(select_columns='i_think_aggression', remove_selected_columns=T, ignore_na = T) %>%
                                       fastDummies::dummy_cols(select_columns='i_say_aggression', remove_selected_columns=T, ignore_na = T) %>%
                                       fastDummies::dummy_cols(select_columns='i_do_aggression', remove_selected_columns=T, ignore_na = T) %>%
  
                                       fastDummies::dummy_cols(select_columns='i_Do_Armed_Unarmed', remove_selected_columns=T, ignore_na = T) %>%
                                       fastDummies::dummy_cols(select_columns='i_do_Act_Interact', remove_selected_columns=T, ignore_na = T) %>%  
                                       fastDummies::dummy_cols(select_columns='i_Think_Type_L0', remove_selected_columns=T, ignore_na = T) %>%
                                       fastDummies::dummy_cols(select_columns='i_Say_Type_L0', remove_selected_columns=T, ignore_na = T) %>%
                                       fastDummies::dummy_cols(select_columns='i_Do_Type_L0', remove_selected_columns=T, ignore_na = T) %>%
                                       fastDummies::dummy_cols(select_columns='i_Leaf_Simplified', remove_selected_columns=T, ignore_na = T) %>%
                                       group_by(i_email_id,index) %>%
                                        summarise_all(max, na.rm=T) %>% #max not sum
                                       ungroup() %>%
                                       mutate_if(is.numeric, function(x) ifelse(is.infinite(x), 0, x))
dim(events_wide_i) #113049    116
#events_wide_j <- events_wide_i
#names(events_wide_j) <- events_wide_j %>% names() %>% str_replace("^i_","j_")
#dim(events_wide_j) #67558   106
```

Let's take this in stages, how many events should be in that sentence?

```{r}

events_wide_i_event_count <- events_wide_i %>% 
                             dplyr::select(icb_survey_version, crisno,section,sentence_number_int_aligned,index,i_email_id,contains('Event_Count')) %>% 
                             mutate(index=index %>% str_replace("_[A-Za-z].*$",'')) %>% 
                             #mutate(crisis=crisis %>% str_replace("_[A-Za-z].*$",'')) %>% 
                             group_by(crisno,section,index, i_email_id) %>%
                             summarise_all(max, na.rm=T) %>%
                             janitor::clean_names() %>%
                             dplyr::select(-i_event_count_na) %>%
                             mutate(i_event_count_thresholded= ((i_event_count_1 + i_event_count_2 + i_event_count_3)>0 )%>% as.numeric())

#First decide whether 0 or more
#Then decide given that why or how many

events_wide_i_event_count_thresholded <- events_wide_i_event_count %>% 
                                         dplyr::select(icb_survey_version, index,i_email_id,crisno,section,sentence_number_int_aligned,i_event_count_thresholded) %>%
                                         mutate(expert=i_email_id %>% str_detect('grad') %>% as.numeric() )


events_wide_i_event_count_thresholded %>% saveRDS(paste0(here::here(), '/data_temp/events_wide_i_event_count_thresholded.Rds'))

```

```{r}

library(tidyverse)
events_wide_i_event_count_thresholded <- readRDS(paste0(here::here(), '/data_temp/events_wide_i_event_count_thresholded.Rds'))


library(brms)
xy_train <- events_wide_i_event_count_thresholded %>% 
  arrange(icb_survey_version, crisno, sentence_number_int_aligned) %>%
  filter(!is.na(section)) %>% #there is exactly one mising value for section and I don't know why
  group_by(i_email_id) %>%
     mutate(i_email_id_count=n()) %>%
  ungroup() %>%
  filter(i_email_id_count>100) #%>% #only care about grads with more than 100 coders
  #head(12000) #First confirm that we can fit all this with STAN and it matches
  #
dim(xy_train) #44743
xy_train$index %>% unique() %>% length() #1k #1500 #12332
xy_train$i_email_id %>% unique() %>% length() #76 #113

#xy_predict <- xy_train %>% 
#              dplyr::filter(i_email_id %>% str_detect('grad')) %>% ungroup()  %>%
#              tidyr::expand(crossing(index, i_email_id)) %>%
#              left_join(xy_train %>% dplyr::select(icb_survey_version, index, crisno, section,sentence_number_int_aligned) %>% distinct() %>% mutate(expert=1) )

#https://www.muscardinus.be/2017/07/lme4-random-effects/
#Implicit nesting
#With implicit nesting, the nesting is ‘defined’ in the data. That is each level of a random effect has a one-to-many relation with the levels of the lower random effect. E.g. each class id is unique for a given class in a given #school and cannot refer to a class in any other school. This is how we constructed the class2 variable in our data. With implicit nesting the code can be abbreviated to (1|A) + (1|B). Note that the (1|A) + (1|A:B) and (1|A/B) #notations remain valid.

#Full interaction
#This takes a long time to compile for some reason
formula_event_count <- bf(i_event_count_thresholded ~ 
                            1 + #an intercept across all sentences
                            # + #each crisis might have more or less events, Cuban Missile should be pretty weird and we probably want to handle it carefully
                            # + #we know the sections are different
                            #section +
                            #expert +
                            #section:expert +
                            #expert + #This is like a global intercept for expert
                            (1 + section + crisno | i_email_id) + #we additionally think individual coders behaved differently even when on the same text
                            #We let each sentence's theta have an novice level and an expert level
                            (1 + expert + icb_survey_version | index)  # + #leaving the properties of the sentence itself
                            #We let each crisis have an effect that varies by section
                            #(1 |  crisno)   #leaving the properties of the sentence itself
)

formula_event_count <- bf(i_event_count_thresholded ~ 
                            1 + 
                            (1 + section + crisno | i_email_id) 
                            (1 + expert + icb_survey_version | index)  
)

xy_train$w <- xy_train$expert*10 #experts are worth 10 undergrads
formula_event_count <- bf(i_event_count_thresholded|weights(w) ~ 
                            1 + 
                            icb_survey_version +
                            (1 | i_email_id) +
                            (1 | index) #+ expert   #conditioning on expert makes the model so slow
)


#library(lme4)
#lme_rasch = glmer(formula_event_count,
#                  xy_train, 
#                  family=binomial(link='logit'))
#summary(lme_rasch, cor=F)


get_prior(formula_event_count,
          data = xy_train,
          family = brmsfamily("bernoulli", "logit")
          )

#Pick some weak but at least not uniform priors
prior_event_count <- 
  prior("normal(0, 3)", class = "sd")  #+ 
  #The two random effects get priors, the fixed effects don
  #prior("cauchy(0,3)", class = "sd")  + 
  #prior("normal(0, 3)", class = "sd", group = "index") +
  #prior("normal(0, 3)", class = "sd", group = "i_email_id") #+
  prior("normal(0, 3)", class = "b") #+
  #prior("normal(0, 3)", class = "Intercept", group = "expert") 


library(cmdstanr)
#install_cmdstan(cores = 4)
#We don't actually care about running this, we just want it to create the rstan for us to feed into numpyo
#oh fun, I have no way of knowing if these coefficients are ordered the same way in both numpyro and here. Better hope so.
file_rstan=paste0(here::here(), "/data_temp/fit_event_count/fit_event_count_fornumpyro.rstan")
fit_event_count_fornumpyro <- brm(
  formula = formula_event_count,
  data = xy_train, 
  family = brmsfamily("bernoulli", "logit"),
  prior = prior_event_count,
  file = paste0(here::here(), "/data_temp/fit_event_count/fit_event_count_fornumpyro"),
  save_model=file_rstan,
  #opencl = opencl(c(0, 0)),
  backend = "cmdstan",
  file_refit="always",
  warmup=1,
  iter=2,
  chains = 1, 
  cores = 1 
)

#Efit out the prior only part because it throws numpyro
tx  <- readLines(file_rstan) %>% paste(collapse="\n") #there's already a\n
tx  <- gsub(pattern = "  if \\(!prior_only\\) \\{", replace = "", x = tx)
tx  <- gsub(pattern = "  \\}\n  // priors including constants", replace = "", x = tx)
writeLines(tx, con=file_rstan)

#It looks like we can make the stan data here
standata_fornumpyro <- make_standata(
  formula = formula_event_count,
  data = xy_train, 
  family = brmsfamily("bernoulli", "logit"),
  warmup=1,
  iter=2,
  chains = 1, 
  cores = 1 
)


```


#need this too
```{r}

#Looks like the exact ordering of the fixed effects, good
colnames(standata_fornumpyro$X)

#fit_event_count_fornumpyro_summary <- summary(fit_event_count_fornumpyro)
#fit_event_count_fornumpyro_summary$fixed #IF these are in the same order then they match up
#Doesn't get us the random effects though

#fit_event_count_fornumpyro_coef <- coef(fit_event_count_fornumpyro) #This probably does but takes forever

```

```{r}

#Setting the priors radically slows it down now and I don't know why
fit_stan=F
library(tictoc)
if(fit_stan){
  tictoc::tic()
    file_rstan=paste0(here::here(), "/data_temp/fit_event_count/fit_event_count_fornumpyro.rstan")
    fit_event_count_for_comparison <- brm(
      formula = formula_event_count,
      data = xy_train, 
      family = brmsfamily("bernoulli", "logit"),
      prior = prior_event_count,
      file = paste0(here::here(), "/data_temp/fit_event_count/fit_event_count_fornumpyro"),
      save_model=file_rstan,
      #opencl = opencl(c(0, 0)), #is much slower for some reason
      backend = "cmdstan",
      file_refit="always",
      warmup=1000,
      iter=2000,
      chains = 4, 
      cores = 64,
      threads = threading(8)
    ) #is actually pretty fast on small models
  tictoc::toc() #Providing less prior made this go slower
  #takes about 10 minutes for 2k
  #Whole thing runs in 10 minutes now with reasonable priors and threading 8
  #17 seconds for 2k
  #threading(4) 116
  #threading(8) 90
  #threading(16) 189
  #Much faster with reasonable priors, gets it down to 90 seconds
  
  
  fit_event_count_for_comparison_coef <- coef(fit_event_count_for_comparison, probs = c(0.05,0.25,0.75, 0.95))
  fit_event_count_for_comparison_fixef <- fixef(fit_event_count_for_comparison)
  fit_event_count_for_comparison_ranef <- ranef(fit_event_count_for_comparison, probs = c(0.05, 0.95))

  sentences <- xy_train %>% group_by(index,expert) %>% 
    summarise(
                i_event_count_thresholded_pos=sum(i_event_count_thresholded==1),
                i_event_count_thresholded_neg=sum(i_event_count_thresholded==0)
              ) %>%
    mutate(i_event_count_thresholded_total=i_event_count_thresholded_pos-i_event_count_thresholded_neg) %>%
    pivot_longer(cols=i_event_count_thresholded_pos:i_event_count_thresholded_total) %>%
    mutate(name=name %>% paste0("_expert",expert)) %>% dplyr::select(-expert) %>%
    pivot_wider(id_cols=index) %>%
    rowwise() %>%
      mutate(i_event_count_thresholded_total= sum(i_event_count_thresholded_total_expert0,i_event_count_thresholded_total_expert1, na.rm=T)) %>%
    ungroup()
  sentences$theta <- fit_event_count_for_comparison_ranef$index[,, "Intercept"][,1] #The direction isn't identified so we have to flip this so it matches whatever the highest score is
  sentences$theta_Q5 <- fit_event_count_for_comparison_ranef$index[,, "Intercept"][,3] #The direction isn't identified so we have to flip this so it matches whatever the highest score is
  sentences$theta_Q95 <- fit_event_count_for_comparison_ranef$index[,, "Intercept"][,4] #The direction isn't identified so we have to flip this so it matches whatever the highest score is

  
  
  
  tictoc::tic()
    file_rstan_SVI=paste0(here::here(), "/data_temp/fit_event_count/fit_event_count_SVI.rstan")
    fit_event_count_for_comparison_SVI <- brm(
      formula = formula_event_count,
      data = xy_train, 
      family = brmsfamily("bernoulli", "logit"),
      prior = prior_event_count,
      file = paste0(here::here(), "/data_temp/fit_event_count/fit_event_count_SVI"),
      save_model=file_rstan_SVI,
      #opencl = opencl(c(0, 0)), #is much slower for some reason
      backend = "rstan", #have to use rstan, there's a bug report that's fixed this but not merged for cmdstan https://github.com/paul-buerkner/brms/issues/1189
      file_refit="always",
      #warmup=1000,
      iter=10000,
      chains = 4, 
      cores = 64,
      #threads = threading(8),
      algorithm = "meanfield",
      tol_rel_obj = 0.000000001
    ) #is actually pretty fast on small models
  tictoc::toc() #Providing less prior made this go slower
  
}

fit_event_count_for_comparison_summary <- summary(fit_event_count_for_comparison)
fit_event_count_for_comparison_SVI_summary <- summary(fit_event_count_for_comparison_SVI) #ok we're getting comparable results now

#Ok with reasonable priors for SVI and it agree
cor(fit_event_count_for_comparison_SVI_summary$fixed$Estimate, fit_event_count_for_comparison_summary$fixed$Estimate)
plot(fit_event_count_for_comparison_SVI_summary$fixed$Estimate, fit_event_count_for_comparison_summary$fixed$Estimate)

fit_event_count_for_comparison_coef <- coef(fit_event_count_for_comparison)
fit_event_count_for_comparison_SVI_coef <- coef(fit_event_count_for_comparison_SVI)

cor(fit_event_count_for_comparison_coef$index[,, "Intercept"][,1], fit_event_count_for_comparison_SVI_coef$index[,, "Intercept"][,1]) #0.9962559
plot(fit_event_count_for_comparison_coef$index[,, "Intercept"][,1], fit_event_count_for_comparison_SVI_coef$index[,, "Intercept"][,1])


cor(sentences$theta,sentences$i_event_count_thresholded)

```



```{r coef-item-va-1pl, echo=FALSE, fig.width=8, fig.cap = "Posterior means and 95\\% credible intervals of item parameters as estimated by model \\code{fit\\_va\\_1pl}."}
#coef_fit_event_count <- coef(fit_event_count)


fit_event_count_for_comparison_coef$index[, , "Intercept"] %>%
	as_tibble() %>% 
  #head(1000) %>%
  arrange(Estimate) %>%
	rownames_to_column() %>%
	rename(item = "rowname") %>%
	mutate(item = as.numeric(item)) %>%
	ggplot(aes(item, Estimate, ymin = Q5, ymax = Q95)) +
	geom_pointrange(aes(item, Estimate, ymin = Q5, ymax = Q95),color="grey", alpha=.2) +
	geom_pointrange(aes(item, Estimate, ymin = Q25, ymax = Q75),color="orange", alpha=.2) +
	geom_point(aes(item, Estimate),color="black", alpha=.2) +
	coord_flip() +
  ggtitle("Evidence that Sentence Has Event(s)",
          subtitle = "Bayesian IRT Model") +
	xlab( "Crisis_Sentence") +
	ylab( "Latent Variable- Sentence has event(s)") 
  


```

```{r coef-item-va-1pl, echo=FALSE, fig.width=8, fig.cap = "Posterior means and 95\\% credible intervals of item parameters as estimated by model \\code{fit\\_va\\_1pl}."}

fit_event_count_for_comparison_coef$i_email_id[, , "Intercept"] %>%
  as.data.frame() %>%
  rownames_to_column() %>%
	as_tibble() %>%
  arrange(Estimate) %>%
  mutate(rowname=fct_reorder(rowname, Estimate)) %>%
	#rownames_to_column() %>%
  mutate(expert=rowname %>% str_detect("grad")) %>%
	#rename(item = "rowname") %>%
	#mutate(item = as.numeric(item)) %>%
	ggplot(aes(rowname, Estimate, ymin = Q2.5, ymax = Q97.5, color=expert)) +
	geom_pointrange() +
	coord_flip() +
	labs(x = "i_email_id")

```



```{r coef-item-va-1pl, echo=FALSE, fig.width=8, fig.cap = "Posterior means and 95\\% credible intervals of item parameters as estimated by model \\code{fit\\_va\\_1pl}."}

fit_event_count_for_comparison_coef$crisno[, , "Intercept"] %>%
  as.data.frame() %>%
  rownames_to_column() %>%
	as_tibble() %>%
  arrange(Estimate) %>%
  mutate(rowname=fct_reorder(rowname, Estimate)) %>%
	#rownames_to_column() %>%
  #mutate(expert=rowname %>% str_detect("grad")) %>%
	#rename(item = "rowname") %>%
	#mutate(item = as.numeric(item)) %>%
	ggplot(aes(rowname, Estimate, ymin = Q2.5, ymax = Q97.5)) +
	geom_pointrange() +
	coord_flip() +
	labs(x = "crisno")

```



```{python}

#Somehow 4k took numpyro 27 minutes which makes me think either it isn't optimized correctly or I've screwed up the cpu configuration. Going to switch to GPU and hope that fixes it.
import os
cwd = os.getcwd()
os.chdir('/mnt/8tb_a/rwd_github_private/ICBEdataset/data_temp/fit_event_count/')) #even though I changed it, it went and put the tmp file back in paper
from stannumpyro import NumPyroModel
from jax import random

import numpyro
import numpyro.distributions as dist
import jax
numpyro.set_platform("gpu")
#numpyro.set_host_device_count(4) #If on cpu pick the number of chains you expect to run
print(jax.__version__)
print(numpyro.__version__)
print(jax.config.FLAGS.jax_backend_target)
print(jax.lib.xla_bridge.get_backend().platform)

if __name__ == "__main__":

    stanfile = "/mnt/8tb_a/rwd_github_private/ICBEdataset/data_temp/fit_event_count/fit_event_count_fornumpyro.rstan"
    #eval $(opam env) #has to be run, currently doing it in profile
    #It doesn't let you run this twice! Had to restart python to get it to switch names
    #If you specify a build folder it throws an errob tu does make it
    model = NumPyroModel(stanfile=stanfile, recompile=True, mode='comprehensive', compiler=['stanc'] ) 
    
    data1 = {
        'J': 8,
        'y': [28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0],
        'sigma': [15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0]
    }
    
    data=r.standata_fornumpyro
    
    #Lists wasn't the problem
    #data_2=data
    #for key in data_2.keys():
    #  if type(data_2[key])==type(np.array(0)):
    #    data_2[key]=data_2[key].tolist()
    #data['grainsize']=100 #For some reason it expecs a grain size switched to commander stand and didn't get this error
    
    mcmc = model.mcmc(
        samples = 2000,
        warmups = 1000,
        chains=1,
        thin=1,
    ) #minute 40 for 2k samples 500 warmup 1 chain
    #falling back to cpu did not fix this error
    #TypeError: true_fun and false_fun output must have same type structure,
    #got PyTreeDef((None, CustomNode(<class 'numpyro.contrib.control_flow.util.PytreeTrace'>[({'_expr__8': {'_control_flow_done': True, 'type': 'sample', 'name': '_expr__8', 'kwargs': {'rng_key': None, 'sample_shape': ()}, 'scale': None, 'is_observed': True, 'cond_indep_stack': [], 'infer': {}}}, ['_expr__8'])], [{'_expr__8': {'args': (), 'fn': CustomNode(<class 'numpyro.distributions.distribution.Unit'>[None], [*]), 'intermediates': [], 'value': *}}]))) and
    #PyTreeDef((None, CustomNode(<class 'numpyro.contrib.control_flow.util.PytreeTrace'>[({}, [])], [{}]))).
    
    mcmc.run(random.PRNGKey(0), data) #amazingly it works #it can't handle threaded version
    print(mcmc.summary())
    results=mcmc.summary() #ok the first betas are the fixed effects

#ok 4 chains is 1:51 on cpu with numpyro    
  
```

```{r}
py$results %>% View()

```


```{r}

#Just in practical terms, 40k takes way too long.

#install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
#install_cmdstan()
library(cmdstanr)
#unlink(paste0(here::here(), "/data_temp/model_fits"), force = T, recursive = T)
library(tictoc)
tic()
  fit_event_count <- brm(
    formula = formula_event_count,
    data = xy_train, 
    family = brmsfamily("bernoulli", "logit"),
    prior = prior_event_count,
    file = paste0(here::here(), "/data_temp/fit_event_count/fit_event_count"),
    save_model=paste0(here::here(), "/data_temp/fit_event_count/fit_event_count.rstan"),
    chains = 4, 
    cores = 64, 
    #opencl = opencl(c(0, 0)),
    backend = "cmdstanr",
    threads = threading(4) #4k 0 was 17.2 #2 was 20.1, #4 was 15.1  #8 was 15.3 , 16 was 18.1
    #107.4 seconds., 4 69.5 seconds 8 77.7
    #20k 4 662.3
  )
toc()

pp <- predict(fit_event_count, newdata=xy_predict, probs = c(0.1, 0.90))

xy_predicted <- cbind(xy_predict , pp)

xy_predicted %>% 
  group_by(index, crisno,section,sentence_number_int_aligned) %>% 
  summarize(Estimate=mean(Estimate)) %>% 
  arrange(crisno,section,sentence_number_int_aligned) %>%
  left_join(xy_train %>% 
              filter(expert==1) %>%
              group_by(index) %>% 
              summarise(expert_mean= sum(i_event_count_thresholded)/length(i_event_count_thresholded) %>% round(2))
                        ) %>%
  left_join(xy_train %>% 
            filter(expert==0) %>%
            group_by(index) %>% 
            summarise(novice_mean= sum(i_event_count_thresholded)/length(i_event_count_thresholded) %>% round(2))
                      ) %>%
  left_join(xy_train %>% 
            #filter(expert==0) %>%
            group_by(index) %>% 
            summarise(all_mean= sum(i_event_count_thresholded)/length(i_event_count_thresholded) %>% round(2))
                      ) %>%
  View()

```

```{r}
summary(fit_event_count)
coef_fit_event_count <- coef(fit_event_count)
```


```{r}
coef_fit_event_count$index[, , "Intercept"] %>%
	as_tibble() %>% 
  View()
```


Ok wow, coder proclivities don't vary at all which means something very wrong has happened


```{r}
#

library(brms)
fit_event_count <- brm(
  formula = formula_event_count,
  data = xy_train, 
  family = brmsfamily("bernoulli", "logit"),
  prior = prior_event_count,
  file = paste0(here::here(), "/data_temp/fit_event_count/fit_event_count"),
  save_model=paste0(here::here(), "/data_temp/fit_event_count/fit_event_count.rstan"),
  chains = 4, 
  cores = 64, 
  #opencl = opencl(c(0, 0)),
  backend = "cmdstanr",
  iter = 1,
  warmup = 1,
  file_refit='always'
  #threads = threading(4) #killing the threads so the model is written simpler
)

```





```{r}

if (!require(devtools)) {
  install.packages("devtools")
}
#devtools::install_github("paul-buerkner/brms", build_vignettes = FALSE)
library(brms)


```

```{r}
data("VerbAgg", package = "lme4")
```

```{r head-VerbAgg, echo=FALSE}
head(VerbAgg, 10) %>%
	kable(
    caption = "First ten rows of the \\texttt{VerbAgg} data.",
    booktabs = TRUE,
    escape = FALSE
	)
```

Let us start by computing a simple 1PL model. For reasons discussed in Section
\ref{model}, I prefer to partially pool person and item parameters by specifying the
model as

```{r}
formula_va_1pl <- bf(r2 ~ 1 + (1 | item) + (1 | id))
```

If we wanted to specify non-hierarchical item parameters, instead,
we would have had to use the formula

```{r, eval = FALSE}
bf(r2 ~ 0 + item + (1 | id))
```

To impose a small amount of regularization on the model, I set
$\text{half-normal}(0, 3)$ priors on the hierarchical standard deviations of
person and items parameters. Given the scale of the logistic response function,
this can be regarded as a weakly informative prior.

```{r}
prior_va_1pl <- 
  prior("normal(0, 3)", class = "sd", group = "id") + 
  prior("normal(0, 3)", class = "sd", group = "item")
```

The model is then fit as follows:

```{r, include=FALSE}
fit_va_1pl <- brm(
  formula = formula_va_1pl,
  data = VerbAgg, 
  family = brmsfamily("bernoulli", "logit"),
  prior = prior_va_1pl,
  file = paste0(here::here(), "/data_temp/model_fits/fit_va_1pl")
)
fit_va_1pl <- add_criterion(fit_va_1pl, "loo")
```

```{r, eval=FALSE}
fit_va_1pl <- brm(
  formula = formula_va_1pl,
  data = VerbAgg, 
  family = brmsfamily("bernoulli", "logit"),
  prior = prior_va_1pl
)
```

To get a quick overview of the model results and convergence, we can summarize
the main parameters numerically using the `summary` method:

```{r}
summary(fit_va_1pl)
```

A graphical summary of the marginal posterior densities as well as the MCMC
chains is obtained via 

```{r plot-va-1pl, fig.width=8, fig.cap="Summary of the posterior distribution of selected parameters obtained by model \\code{fit\\_va\\_1pl.}"}
plot(fit_va_1pl)
```


```{r coef-item-va-1pl, echo=FALSE, fig.width=8, fig.cap = "Posterior means and 95\\% credible intervals of item parameters as estimated by model \\code{fit\\_va\\_1pl}."}
coef_fit_va_1pl <- coef(fit_va_1pl)
coef_fit_va_1pl$item[, , "Intercept"] %>%
	as_tibble() %>%
	rownames_to_column() %>%
	rename(item = "rowname") %>%
	mutate(item = as.numeric(item)) %>%
	ggplot(aes(item, Estimate, ymin = Q2.5, ymax = Q97.5)) +
	geom_pointrange() +
	coord_flip() +
	labs(x = "Item Number")


```


```{r coef-person-va-1pl, echo=FALSE, fig.width=8, fig.height = 4, fig.cap = "Posterior means and 95\\% credible intervals of person parameters (sorted) as estimated by model \\code{fit\\_va\\_1pl}."}
ranef_va_1pl <- ranef(fit_va_1pl)
ranef_va_1pl$id[, , "Intercept"] %>%
	as_tibble() %>%
	rownames_to_column() %>%
	select(-Est.Error) %>%
	arrange(Estimate) %>%
	mutate(id = seq_len(n())) %>%
	ggplot(aes(id, Estimate, ymin = Q2.5, ymax = Q97.5)) +
	geom_pointrange(alpha = 0.7) +
	coord_flip() +
	labs(x = "Person Number (Sorted)")
```

Above, I split up the non-linear model into two parts, `eta` and `logalpha`,
each of which is in turn predicted by a linear formula. The parameter `eta`
represents the sum of person parameter and item easiness, whereas `logalpha`
represents the log discrimination. I modeled item easiness and discrimination
as correlated by using `|i|` in both varying item terms (see Section
\ref{brms}). I impose weakly informative priors both on the intercepts of
`eta` and `logalpha` (i.e., on the overall easiness and log discrimination) as
well as on the standard deviations of person and item parameters.

```{r}
formula_va_2pl <- bf(
  r2 ~ exp(logalpha) * eta,
  eta ~ 1 + (1 |i| item) + (1 | id),
  logalpha ~ 1 + (1 |i| item),
  nl = TRUE
)
```


```{r}
prior_va_2pl <- 
  prior("normal(0, 5)", class = "b", nlpar = "eta") +
  prior("normal(0, 1)", class = "b", nlpar = "logalpha") +
  prior("constant(1)", class = "sd", group = "id", nlpar = "eta") + 
  prior("normal(0, 3)", class = "sd", group = "item", nlpar = "eta") +
  prior("normal(0, 1)", class = "sd", group = "item", nlpar = "logalpha")
```


```{r, include = FALSE}
fit_va_2pl <- brm(
	formula = formula_va_2pl,
  data = VerbAgg, 
	family = brmsfamily("bernoulli", "logit"),
	prior = prior_va_2pl,
	inits = 0,
	file = paste0(here::here(), "/data_temp/model_fits/fit_va_2pl")
)
fit_va_2pl <- add_criterion(fit_va_2pl, "loo") 
```

```{r, eval = FALSE}
fit_va_2pl <- brm(
  formula = formula_va_2pl,
  data = VerbAgg, 
  family = brmsfamily("bernoulli", "logit"),
  prior = prior_va_2pl,
) 
```

```{r coef-item-va-2pl, echo=FALSE, fig.width=8, fig.height = 4, fig.cap="Posterior means and 95\\% credible intervals of item parameters as estimated by model \\code{fit\\_va\\_2pl}."}
coef_fit_va_2pl <- coef(fit_va_2pl)
eta <- coef_fit_va_2pl$item[, , "eta_Intercept"] %>%
	as_tibble() %>%
	rownames_to_column() 
alpha <- coef_fit_va_2pl$item[, , "logalpha_Intercept"] %>%
	exp() %>%
	as_tibble() %>%
	rownames_to_column()
bind_rows(eta, alpha, .id = "nlpar") %>%
	select(-Est.Error) %>%
	rename(item = "rowname") %>%
	mutate(item = as.numeric(item)) %>%
	mutate(nlpar = factor(nlpar, labels = c("Easiness", "Discrimination"))) %>%
	ggplot(aes(item, Estimate, ymin = Q2.5, ymax = Q97.5)) +
	facet_wrap("nlpar", scales = "free_x") +
	geom_pointrange() +
	coord_flip() +
	labs(x = "Item Number")
```


Diads

```{r}
#This is going to be a million?
diads_wide <-  events_wide_i %>%
               left_join(events_wide_j, by=c('index'='index') ) %>% 
               filter(i_email_id!=j_email_id) %>% 
               #rowwise() %>%
               mutate(ij_email_id= ifelse( i_email_id>=j_email_id,paste0(i_email_id,j_email_id),paste0(j_email_id,i_email_id) ) ) %>%
               mutate(index_ij_email_id=paste0(index,ij_email_id)) %>%
               filter(!duplicated(index_ij_email_id)) %>%
               arrange(index) %>%
               ungroup() %>%
               mutate_if(is.numeric, function(x) ifelse(is.infinite(x), 0, x))
dim(diads_wide) #204,781    213


variables <- setdiff( names(diads_wide) %>% str_replace("ij_|i_|j_","") %>% unique(), c('index_ij_email_id','email_id','index',"ij_email_id","index_ij_email_id","match_i_email_id","index_email_id"  ))
diads_wide <- as.data.frame(diads_wide)
for(q in variables){
  print(q)
  newvar <- paste0("match_",q)
  a_oldvar <- paste0("i_",q)
  b_oldvar <- paste0("j_",q)
  diads_wide[,newvar] <-  0 #default 0
  diads_wide[,newvar] <-  ifelse(diads_wide[,a_oldvar] %in% 1 &  diads_wide[,b_oldvar] %in% 1, 1,  diads_wide[,newvar])  #if both 1 then 1
  diads_wide[,newvar] <-  ifelse(diads_wide[,a_oldvar] %in% 0 &  diads_wide[,b_oldvar] %in% 0, NA, diads_wide[,newvar])  #if both 0 then NA
}

diads_matches <- diads_wide %>% 
                 dplyr::select(index_ij_email_id,  starts_with("match"))  %>%
                 dplyr::select(-ends_with("_NA")) 
  
final_counts_numerator <- diads_matches %>% summarise_if(is.numeric, sum, na.rm=T)
final_counts_denominator <- diads_matches %>% summarise_if(is.numeric, ~sum(is.finite(.x)) )

final_scores <- final_counts_numerator / final_counts_denominator
#One takeaway is that because coders split on act vs interact is artificially drops the agreement

#New plan, we're going to pull out those dimensions seperately
#final_scores %>% round(2) %>% t()  %>% as.data.frame() %>%  tibble::rownames_to_column( "VALUE") %>% View()
options(warn=0)

final_scores_df <- data.frame(varname= names(final_scores),  final_scores=final_scores %>% round(2) %>% t(),final_counts_numerator=final_counts_numerator%>% t()) %>% filter(final_counts_numerator>1)
#final_scores_df %>% View() 
#cor(final_scores_df) #.64 correlation between agreement and how often its used

p_intercoder_agreement <- final_scores_df %>%
                                  mutate(grouping=NA) %>%
                                  mutate(grouping=ifelse(varname %>% str_detect('Event_Count'), 'Event_Count' ,  grouping)) %>%
                                  mutate(grouping=ifelse(varname %>% str_detect('match_Behavior_'), 'Behavior' ,  grouping)) %>%
                                  mutate(grouping=ifelse(varname %>% str_detect('think_aggression'), 'Aggression (think)' ,  grouping)) %>%
                                  mutate(grouping=ifelse(varname %>% str_detect('say_aggression_'), 'Aggression (say)' ,  grouping)) %>%
                                  mutate(grouping=ifelse(varname %>% str_detect('do_aggression_'), 'Aggression (do)' ,  grouping)) %>%
                                  mutate(grouping=ifelse(varname %>% str_detect('Do_Armed_Unarmed'), 'Armed or Unarmed Agents' ,  grouping)) %>%
                                  mutate(grouping=ifelse(varname %>% str_detect('do_Act_Interact'), 'Action or Interaction' ,  grouping)) %>%
                                  mutate(grouping=ifelse(varname %>% str_detect('Think_Type_L0'), 'Think (L0)' ,  grouping)) %>%
                                  mutate(grouping=ifelse(varname %>% str_detect('Say_Type_L0'), 'Say (L0)' ,  grouping)) %>%
                                  mutate(grouping=ifelse(varname %>% str_detect('Do_Type_L0'), 'Do (L0)' ,  grouping)) %>%
                                  mutate(grouping=ifelse(varname %>% str_detect('Leaf_Simplified'), 'Leaf Simplified' ,  grouping)) %>%
                                  mutate(grouping=grouping %>% factor(levels=c('Event_Count', 'Behavior','Aggression (think)','Aggression (say)','Aggression (do)',
                                                                               'Armed or Unarmed Agents','Action or Interaction',
                                                                               'Think (L0)','Say (L0)','Do (L0)','Leaf Simplified') %>% rev() ) ) %>%
                                  ggplot(aes(x=final_scores, y=grouping)) + 
                                  geom_boxplot() +
                                  xlab("Intercoder Agreemnt (Experts, positives only, Single Event Sentences)") +
                                  ylab("Psuedo Ontology Tree Depth")

```


```{r, eval=F}
p_intercoder_agreement
```

