---
title: 'Intercoder Agreement'
site: bookdown::bookdown_site
bibliography: ../ICBintro.bib
output: 
  rticles::arxiv_article:
    keep_tex: true
header-includes:
  - \usepackage[utf8]{inputenc}
  - \usepackage{pifont}
  - \usepackage{newunicodechar}
  - \newunicodechar{✓}{\ding{51}}
  - \newunicodechar{✗}{\ding{55}}
  - \usepackage{array}
  - \usepackage{ctable} # added for demo
  - \usepackage{natbib} #added for latex citation within huxtable
  - \usepackage{booktabs}
  - \usepackage{longtable}
  - \usepackage{array}
  - \usepackage{multirow}
  - \usepackage{wrapfig}
  - \usepackage{colortbl}
  - \usepackage{pdflscape}
  - \usepackage{tabu}
  - \usepackage{threeparttable}
  - \usepackage{threeparttablex}
  - \usepackage[normalem]{ulem}
  - \usepackage{makecell}
  - \usepackage{titlesec}
  - \usepackage[parfill]{parskip}
  - \usepackage{makecell}
  - \usepackage{graphicx}
  - \usepackage{caption}
  - \usepackage[capposition=top]{floatrow}
  - \titleformat{\subsubsection}{\normalfont\normalsize\itshape}{\thesubsubsection}{1em}{}
  - \titlespacing*{\subsubsection}{0pt}{3.25ex plus 1ex minus .2ex}{0ex plus .2ex}
  - \DeclareUnicodeCharacter{00A0}{ }
  - \usepackage{setspace}
  - \usepackage{cellspace}
  - \setlength\cellspacetoplimit{0.8ex}
  - \renewcommand{\arraystretch}{0.8}
  - \AtBeginEnvironment{tabular}{\singlespacing}
  - \AtBeginEnvironment{lltable}{\singlespacing}
---


# Intro

## Library Loads


```{r}
library(flextable)
library(tidyverse)
library(googlesheets4)



```

```{r}
icb_long_clean <- readRDS(file=paste0(here::here(), "/data/icb_long_clean.Rds")) 

codings_long <- readRDS(paste0(here::here(), '/data_out/codings_long.Rds'))
codings_long_agreement <- readRDS( paste0(here::here(), '/data_out/codings_long_agreement.Rds'))
codings_long_agreed <- readRDS( paste0(here::here(), '/data_out/codings_long_agreed.Rds'))
codings_wide_agreed <- readRDS( paste0(here::here(), '/data_out/codings_wide_agreed.Rds'))


```




Self Reported Confidence and Percent Agreement

```{r}


confidence_totals <- bind_rows(
  icb_long_clean %>% filter(email_id %>% str_detect('expert') & variable_normalized=='raterconfidence' ) %>% count(value_normalized) %>% mutate(coder="expert") %>% mutate(n= (n/sum(n)*100) %>% round(1) %>% paste0("%") ),
  icb_long_clean %>% filter(email_id %>% str_detect('undergrad') & variable_normalized=='raterconfidence' ) %>% count(value_normalized)  %>% mutate(coder="undergrad") %>% mutate(n=(n/sum(n)*100) %>% round(1) %>% paste0("%"))
) %>%
  mutate(confidence=value_normalized %>% factor(levels=c('none','low','high','complete')) %>% as.numeric() ) %>%
  mutate(x=0.05)




c1 <- codings_long_agreement  %>% filter(keep==T) %>% dplyr::select(selected_by_perc=selected_by_any_perc,confidence=confidence)  %>% mutate(name="Accepted_Either")
c2 <- codings_long_agreement %>% dplyr::select(selected_by_perc=selected_by_any_perc,confidence=confidence) %>% mutate(name="Accepted_Either")
c3 <- codings_long_agreement %>% dplyr::select(selected_by_perc=selected_by_experts_perc,confidence=confidence_expert) %>% mutate(name="Experts")
c4 <- codings_long_agreement %>% dplyr::select(selected_by_perc=selected_by_undergrads_perc,confidence=confidence_undergrad) %>% mutate(name="Undergraduates")
bind_rows(c1,c2,c3,c4) %>% na.omit() %>%
  ggplot(aes(x=confidence, y=selected_by_perc, color=name)) + geom_smooth() #geom_point()

library(ggExtra)
p1_confidence_agreement <-   codings_long_agreement %>% #codings_long %>%  codings_long_agreement
    mutate(confidence=confidence %>% round() %>% as.factor() ) %>%
    filter(value_normalized!='') %>%
    filter(total_coders>1) %>% #about 9k only had one coder
    filter(selected_by_experts>=1) %>%
    dplyr::select(variable_normalized,selected_by_any_perc,selected_by_experts_perc,selected_by_undergrads_perc,keep,confidence) %>%
    group_by(confidence) %>%
    summarise(
        Accepted_Either=selected_by_any_perc[keep==1] %>% mean(na.rm=T), 
        Either=selected_by_any_perc %>% mean(na.rm=T), 
        Experts=selected_by_experts_perc %>% mean(na.rm=T), 
        Undergraduates=selected_by_undergrads_perc %>% mean(na.rm=T)
    ) %>%
    filter(!is.na(confidence)) %>%
    #mutate(variable_normalized=fct_reorder(variable_normalized, Either)) %>%
    pivot_longer(c(-confidence)) %>%
    ggplot(aes(x=selected_by_any_perc, y=confidence)) + 
    #geom_boxplot() + 
    geom_point(aes(x=value, color=name )) +
    xlab("Percent of Coders") +
    ylab("Confidence") +
    labs(title = "Percent of Coders who Chose a Tag by Confidence and Type of Coder"#,
          #subtitle = "Plot of length by dose",
          #caption = "Data source: ToothGrowth"
         ) + 
    theme_bw()
p1_confidence_agreement + theme(legend.position="bottom")
  
```

```{r}

#Calculate average agreements by group
means1 <- codings_long_agreement %>% 
              filter(value_normalized!='') %>%
              filter(total_coders>1) %>% #about 9k only had one coder
              #filter(selected_by_experts>=1) %>%
              dplyr::select(All=selected_by_any_perc,Experts=selected_by_experts_perc,Undergraduates=selected_by_undergrads_perc) %>% summarise_all(mean, na.rm=T)
means1_keep <- codings_long_agreement %>% 
      filter(value_normalized!='') %>%
    filter(total_coders>1) %>% #about 9k only had one coder
    #filter(selected_by_experts>=1) %>%
  filter(keep==1) %>% dplyr::select(Accepted=selected_by_any_perc) %>% summarise_all(mean, na.rm=T)
meansall <- bind_rows(means1,means1_keep) %>% mutate(x=1) %>% pivot_longer(cols=c(-x)) %>% na.omit()

#These are all by definition chosen by at least 1
#Do we further require at least 1 expert as with our aggregations?
p_percent_chose_tag_by_concept <- 
  codings_long_agreement %>% #codings_long %>%  codings_long_agreement
    mutate(variable_normalized=variable_normalized %>% str_replace_all("_"," ") %>% tolower() ) %>%
    filter(value_normalized!='') %>%
    filter(total_coders>1) %>% #about 9k only had one coder
    #filter(selected_by_experts>=1) %>%
    dplyr::select(variable_normalized,selected_by_any_perc,selected_by_experts_perc,selected_by_undergrads_perc,keep) %>%
    group_by(variable_normalized) %>%
      summarise(
          N=n(),
          Accepted=selected_by_any_perc[keep==1] %>% mean(na.rm=T), 
          All=selected_by_any_perc %>% mean(na.rm=T), 
          Experts=selected_by_experts_perc %>% mean(na.rm=T), 
          Undergraduates=selected_by_undergrads_perc %>% mean(na.rm=T)
      ) %>%
    filter(N>10) %>%
    dplyr::select(-N) %>%
    mutate(variable_normalized=fct_reorder(variable_normalized, Accepted)) %>%
    pivot_longer(c(-variable_normalized)) %>%
    ggplot(aes(x=selected_by_any_perc, y=variable_normalized)) + 
    #geom_boxplot() + 
    geom_point(aes(x=value, color=name )) +
    xlab("Percent of Coders that selected Tag") +
    ylab("") +
    labs(
      # title = "Intercoder Agreement by Concept/Type",
      # subtitle = "Mean by Concept (points), Mean by Group (Vertical Lines)",
          caption = paste0("Point = mean by concept; Line = mean by group\nUnit of Analysis: Tag chosen by any Coder, N=", codings_long_agreement %>% filter(value_normalized!='') %>% nrow() %>% scales::comma(), "; Accepted Tokens=", codings_long_agreement %>% filter(value_normalized!='' & keep==T) %>% nrow() %>% scales::comma()),
         color = "Codings"
         ) + 
    theme_bw() +
    theme(legend.position="bottom") +
    geom_vline(data=meansall, aes(xintercept = value, color = name), linetype="solid", size=1, alpha=0.5)

```



```{r, eval=T, echo=F, results='markup', include=T, message=F, cache=F, warning=F,  ft.arraystretch=0.75, fig.width=6, fig.height=6}

p_percent_chose_tag_by_concept %>% saveRDS(paste0(here::here(), '/paper/figures/p_percent_chose_tag_by_concept.Rds'))
p_percent_chose_tag_by_concept

ggplot2::ggsave(file=paste0(here::here(), '/paper/figures/p_percent_chose_tag_by_concept.png'), 
                plot = p_percent_chose_tag_by_concept, width=8, height=6)
#table(expert_majority=codings_long$expert_majority,
#      undergrad_majority=codings_long$undergrad_majority)

#58% of tokens including null have agreement from either experts, undergrads, or both
#(table(expert_majority=codings_long$expert_majority,
#      undergrad_majority=codings_long$undergrad_majority) / nrow(codings_long) ) %>% round(2)


#table(codings_long$value_normalized != "")
# FALSE   TRUE 
#480,239 408,126 #about the same number of null tokens as non null ones
```


