---
title: "01_compile_saves"
output:
  html_document:
    df_print: paged
  toc: yes
editor_options:
  chunk_output_type: inline
---

```{=html}
<style>
  body {
    position: absolute;
    left: 0px;
    max-width: 2000px;
  }
body .main-container {
  max-width: 2000px;
}
</style>
```
This notebook walks through the creation of the crisisno-sentenceno-sentence key

Library Loads

```{r}
library(tidyverse)
`%>%` <- magrittr::`%>%`
fromscratch=T #global flag for whether to regenerate files form scratch or load presaved ones

```

Load and anonymize original individual save files from the gui

```{r, include=FALSE}

devtools::load_all(".")

# events <- load_raw_events(fromscratch = F)

```

```{r warning=FALSE}

#Only a project lead can run this code. Copy (NEVER MOVE) the original save files to the data_temp folder. And then verify that that data_temp is on the gitignore list so it never gets committed.
path <- paste0(here::here(), "/git_ignore_folder/icb_worker_saves") #this folder is copied over from the dropbox folder and never committed to github
files_worker_saves <- list.files(path = path, pattern = ".Rdata", all.files = FALSE, full.names = T, recursive = T, ignore.case = FALSE, include.dirs = FALSE)
length(files_worker_saves) #32748

#First confirm how many emails
files_worker_saves %>% str_replace(".*\\/",'') %>% str_replace("_.*",'') %>% unique() %>% length() #141 possible

files_worker_saves <- files_worker_saves[!files_worker_saves %>% str_detect("[0-9][0-9]\\.[0-9][0-9]\\.[0-9][0-9].Rdata")] #exclude the date stamped ones
length(files_worker_saves) #1965
if(length(files_worker_saves)==0){print("Original save files not found locally, will load premade anonymized file instead")
  }else{print("Original save files found, can regenerate anonymized if desired.")}

files_worker_saves %>% str_replace(".*\\/",'') %>% str_replace("_.*",'') %>% unique() %>% length() #140 possible

df <- data.frame(file=files_worker_saves)

```

```{r warning=FALSE}

#Only execute if both (1) the original save files are available locally (2) fromscratch is requested
if(fromscratch & length(files_worker_saves)>0){

    #### CODE TO LOAD EVENT LEVEL DATA

    print(length(files_worker_saves)) #how many saved files we show

    # creates a list of event 'vectors' and names them based on the paths
    icb_worker_saves <- lapply(files_worker_saves, readRDS) #Read the files into memory in parallel
    names(icb_worker_saves) <- files_worker_saves

    # save the path name of with each row
    for(i in 1:length(icb_worker_saves)){
      #print(i)
      icb_worker_saves[[i]]$savefile <- files_worker_saves[i]
    }

    #("/mnt/8tb_a/rwd_github_private/ICBEdataset/replication_data/ignore/icb_worker_saves/nlundumd.edu_163_EGYPT-SUDAN_BORDER_I.Rdata" %>% str_match(pattern="^.*?_([0-9]*)_"))[2]
    # reshape the work rows into a list of dataframes
    icb_worker_saves_dfs_list <- list()
    for(q in names(icb_worker_saves) ){
      #print(q)
      temp=unlist(icb_worker_saves[[q]]); #This is a named vector where names are keys, and values are values. One for every single response for a saved email-crisis.name
      df <- data.frame(varname = names(temp), value = temp, stringsAsFactors = F) #convert to dataframe
      tokens <- strsplit(df$varname,"_")
      icb_worker_saves_dfs_list[[q]]  <- df %>% 
        dplyr::mutate(sentence_number = sapply(tokens, FUN=function(x) x[1])) %>%
        dplyr::mutate(event_number = sapply(tokens, FUN=function(x) x[2])) %>%
        dplyr::mutate(email = df$value[df$varname=="email"]) %>%
        dplyr::mutate(savefile = q) %>% 
        dplyr::mutate(sentence_number_int =  as.numeric(gsub("s","",sentence_number))) %>% #These throw warnings
        dplyr::mutate(event_number_int =  as.numeric(gsub("e","",event_number))) %>%
        dplyr::select(-sentence_number, -event_number ) %>%
        dplyr::filter(!varname %in% 
                        c("email", "input_crisis", "savebutton", "savebutton2", "startbutton", "practice1", "practice2", "practice3", "practice4", "sentencenumber","crisis", "savefile")) %>%
        dplyr::select(-starts_with("sentencenumber") ) %>% 
        filter(value!='') %>%
        filter(!is.na(sentence_number_int)) %>% #there are a few broken questions
        group_by(sentence_number_int) %>%
          dplyr::mutate(input_crisis = value[varname %>% str_detect("crisis") ]) %>%
          dplyr::mutate(crisno = value[varname %>% str_detect("crisno") ]) %>% #You can't actually trust the original gui crisis number, always trust the file name instead
        ungroup() %>%
        #There are two instances where the filename is wrong which is why we go with the GUI reported coding
        #rowwise() %>%
        #  dplyr::mutate(crisno_filenamereported = (savefile %>% str_match("_([0-9]{1,3})_") )[2] %>% as.numeric()  ) %>% #You can't actually trust the original gui crisis number, always trust the file name instead
        #ungroup() %>%
        arrange(sentence_number_int) %>% #make sure you order but sentence int so you select on the first sentence
        #Using spans later I've confirmed that when the gui and the file name disagree, the gui was always right
        #So there's a kind of file that was just completely wrong and there's another kind that had the wrong file named assigned for some reason, e.g. in an earlier gui bug (n=2)
        #So what we're going to do is ask if the gui report varies within a crisis and if so we're going to drop the second that appears and keep the first
        filter(crisno==crisno[1])  #require every one to match the very first gui report one in the file
        #This is what we originally did just using the name of the crisis and not the number
        #filter(input_crisis==input_crisis[1]) #There's a bug where extra sentences were tagged after a gui switch, they have the wrong input crisis which this screens
        #We've now moved rejecting sentences from the wrong narrative to the spans section. We'll check to see if that sentence shows up and if not kill it.
        
      # filter out variables with varnames that contain "sentencenumber"

    }
    length(icb_worker_saves_dfs_list)

    
    
    #table(icb_long$email) %>% sort()
    expert1 <- c("4fb99e72","f1a62076","3ee0cdf1")                                                                  
    expert2 <- c('890f3f5e','a6323005')  
    expert3 <- c("6e1ad8fc","c252a171","e7f1167f")
    expert4 <- c("d9d78123","d7b84c6b","e0741cd9")                                                                  
    expert5 <- c('052c88eb',"77f0bb72")    
    expert6 <- c('7559b489','6158e8c6')       
    expert7 <- c('414ee682') #"example" #was a concensus coding we created for training purposes and should be considered expert                                                                          
    
   	emails_crisno <- dplyr::bind_rows(icb_worker_saves_dfs_list) %>% filter(varname %>% str_detect("sentence_events")) %>% dplyr::count(email, crisno)
    crises_per_coder <- emails_crisno %>% dplyr::count(email)
    sentences_per_coder <- dplyr::bind_rows(icb_worker_saves_dfs_list) %>% filter(varname %>% str_detect("sentence_events")) %>% dplyr::count(email) #this is roughly the number of sentences per coder
    coder_statistics <- sentences_per_coder %>% rename(n_sentences=n) %>% full_join(crises_per_coder  %>% rename(n_crises=n) ) %>%
                          rowwise() %>%
                            dplyr::mutate(email_crc32= digest::digest(email[1],'crc32') )  %>%
                          ungroup() %>%
                          dplyr::mutate(email_id=email_crc32) %>% 
                          dplyr::mutate(email_id= ifelse(email_crc32 %in% expert1, "expert1", email_id)) %>%
                          dplyr::mutate(email_id= ifelse(email_crc32 %in% expert2, "expert2", email_id)) %>%
                          dplyr::mutate(email_id= ifelse(email_crc32 %in% expert3, "expert3", email_id)) %>%
                          dplyr::mutate(email_id= ifelse(email_crc32 %in% expert4, "expert4", email_id)) %>%
                          dplyr::mutate(email_id= ifelse(email_crc32 %in% expert5, "expert5", email_id)) %>%
                          dplyr::mutate(email_id= ifelse(email_crc32 %in% expert6, "expert6", email_id)) %>%
                          dplyr::mutate(email_id= ifelse(email_crc32 %in% expert7, "expert7", email_id)) %>%
                          mutate(status="keep") %>%
                          mutate(status=ifelse( email_crc32 %in% c("6e1ad8fc"), "reject",  status )) %>% #test email account
                          mutate(status=ifelse( email %in% c("unit_test","example"), "reject",  status )) %>% #test email account
                          mutate(status=ifelse( n_crises==1 | n_sentences<66, "reject",  status )) %>%  #only one crisis or less than 66 sentences
                          mutate(status=ifelse( email_crc32 %in% c('414ee682',"e0741cd9","6158e8c6","77f0bb72","3ee0cdf1"), "keep",  status )) %>% #there are few email misspellings we want to keep
                          mutate(expert = email_id %>% str_detect("expert") %>% as.integer()) 
      
    #emails_to_keep <- sentences_per_coder %>% dplyr::filter(n>=88) %>% dplyr::pull(email) #we're going to reject any with less than 88 filled out sentences
    #That's 117
    #emails_to_reject <- crises_per_coder %>% filter(n==1) %>% pull(email)
    icb_long <- dplyr::bind_rows(icb_worker_saves_dfs_list) %>%
                dplyr::filter(value!="") %>% 
                left_join(coder_statistics %>% dplyr::select(email,email_crc32, email_id, status, expert)) %>%
                dplyr::filter(status %in% "keep"  ) %>% 
                dplyr::filter(!is.na(event_number_int) & !is.na(sentence_number_int)) %>% 
      
                dplyr::mutate(varname=stringr::str_replace(varname, "s[0-9]*_e[0-9]*_","")) %>%
                dplyr::mutate(varname=stringr::str_replace(varname, "actor1","actor_a")) %>%
                dplyr::mutate(varname=stringr::str_replace(varname, "actor2","actor_b")) %>%
                dplyr::mutate(varname=stringr::str_replace(varname, "s[0-9]*_","")) %>%
                dplyr::mutate(varname=stringr::str_replace(varname, "[0-9]*$","")) %>%
      
                #This trick lets us replace email addresses without having to write them in the code
                dplyr::group_by(email) %>%
                  dplyr::mutate(email_crc32= digest::digest(email[1],'crc32') ) %>% #anonymize
                dplyr::ungroup() %>%
                  
                dplyr::group_by(savefile) %>%
                dplyr::mutate(savefile_crc32= digest::digest(savefile[1],'crc32') ) %>% #anonymize
                dplyr::ungroup() %>%
                  
                dplyr::select(-email,-savefile) %>% #anonymize

                dplyr::arrange(savefile_crc32, sentence_number_int, event_number_int, varname ) %>%
                group_by(savefile_crc32, sentence_number_int) %>%
                  mutate(sentence=(value[varname=="sentence"][1])) %>%
                ungroup() %>% 
                mutate(sentence_clean= sentence %>% 
                         str_replace("Pre-crisis|Precrisis","") %>% #we
                         str_replace("Background|BACKGROUND","") %>% 
                         str_replace("^\\(","") %>% 
                         str_replace("\\)$","") %>% 
                         str_replace('^ \\\\"',"") %>% 
                         trimws()  ) #%>% 
                #mutate(sentence_hash = paste0(crisno, sentence_clean %>% tolower() %>% str_replace_all("[^a-z]", "" ) ) )
    
    #
    coders_per_crisis <- icb_long %>% dplyr::select(crisno,  email_id, expert) %>% distinct() #%>% dplyr::count(crisno)
    coders_per_crisis_tally <- coders_per_crisis %>% mutate(novice=expert==0) %>% group_by(crisno) %>% summarise( expert=sum(expert==1), novice=sum(novice==1) )
    crisis_sentences_per_coder <- icb_long%>% filter(varname %>% str_detect("sentence_events")) %>% dplyr::count(email_id, crisno)
    #
    #devtools::install_github("ropensci/textreuse", build_vignettes = TRUE)
    #install.packages("text.alignment")
    #library(textreuse)
    library(tictoc)
    library(text.alignment)
    
    if(fromscratch){
      icb_crisis_summaries <- readRDS(here::here("replication_corpus", "data", "out", "icb_corpus_V1.0_May_16_2022.Rds"))
      
      
      
      #Do a round first based on the file name
      icb_long_crisis_sentence_unique <- icb_long %>% dplyr::select(crisno,  sentence_clean) %>% distinct() %>%  #we have to check two different crises, the one that was reported and the file name
        mutate(crisno= crisno %>% as.numeric()) %>%
        left_join(icb_crisis_summaries %>% dplyr::select(crisno,text) ) %>%
        janitor::clean_names()
      icb_long_crisis_sentence_unique$sentence_clean_hash_match_similarty=NA
      icb_long_crisis_sentence_unique$sentence_clean_hash_match_location_start=NA
      icb_long_crisis_sentence_unique$sentence_clean_hash_match_location_end=NA
      #Ya I'm just going to have to remove parenthetical again, there's no avoiding it
      tic()
        for(i in 1:nrow(icb_long_crisis_sentence_unique)){
          #print(i)
          if(i %% 100 ==0) {print(i)}
          if(!is.na(icb_long_crisis_sentence_unique$sentence_clean[i]) & nchar(icb_long_crisis_sentence_unique$sentence_clean[i])>5){ #there are some broken sentences with few or no characters
            temp1 <- text.alignment::smith_waterman(icb_long_crisis_sentence_unique$sentence_clean[i] , icb_long_crisis_sentence_unique$text[i])
            icb_long_crisis_sentence_unique$sentence_clean_hash_match_location_start[i]=temp1$b$alignment$from
            icb_long_crisis_sentence_unique$sentence_clean_hash_match_location_end[i]=temp1$b$alignment$to
            icb_long_crisis_sentence_unique$sentence_clean_hash_match_similarty[i]=temp1$similarity        
          }
        }
      toc() #878.328 sec elapsed
    icb_long_crisis_sentence_unique %>% saveRDS(here::here("replication_corpus", "data", "out", "icb_long_crisis_sentence_unique.Rds"))
    }
    icb_long_crisis_sentence_unique <- readRDS(here::here("replication_corpus", "data", "out", "icb_long_crisis_sentence_unique.Rds"))

    
    
    icb_long_spans <- icb_long %>% 
                      mutate(crisno = crisno %>% as.numeric()) %>%
                      left_join(icb_long_crisis_sentence_unique %>%
                                filter(!is.na(sentence_clean_hash_match_location_start)) %>%
                                rowwise() %>%
                                  mutate(sentence_span_text=text %>% substring(first=sentence_clean_hash_match_location_start, last=sentence_clean_hash_match_location_end) %>% trimws() ) %>%
                                ungroup() %>%
                      dplyr::select(crisno,
                                    sentence_clean,
                                    sentence_span_score=sentence_clean_hash_match_similarty,
                                    sentence_span_start=sentence_clean_hash_match_location_start,
                                    sentence_span_end=sentence_clean_hash_match_location_end,
                                    sentence_span_text
                                    ) 
                      ) %>% dplyr::select(-sentence_number_int) #nuke sentence number here and replace it later based on span
    dim(icb_long_spans) #880,593
    saveRDS(icb_long_spans ,
            file=paste0(here::here(),"/replication_data/in/icb_long_spans.Rds")) #note "input crisis" is broken
  }  else  {
    icb_long_spans <-
      readRDS(file=paste0(here::here(),"/replication_data/in/icb_long_spans.Rds"))
}

```
