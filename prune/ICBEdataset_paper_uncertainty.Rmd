---
title: "Uncertainty"
output: html_document
---

# Intro

## Library Loads


```{r}
library(flextable)
library(tidyverse)

```


```{r}

#Takes a while
rex_paste <- function(x) { x %>% unique() %>% na.omit() %>% sort() %>% paste0(sep=";", collapse=";")}
rex_count <- function(x) { x %>% unique() %>% na.omit() %>% sort() %>% paste0(sep=";", collapse=";")}

```
## Hand coded aggregations

```{r}
target_file <- paste0(here::here(),"/replication_paper/data/in/icbe_litreview,_trees_sentences.xlsx")
full_tree    <- readxl::read_excel(target_file, sheet="Codebook in Tree Form")

full_tree <- full_tree %>% filter(!is.na(Leaf) & Leaf!='')
#The leafs aren't unique here because you can get to the same branch multiple ways

#This ignores conditions FYI
#Behavior # 3 bits
#think_aggression #1 bit
#say_aggression #1 bit
#do_aggression #1 bit
#Do_Armed_Unarmed #1 bit
#do_Act_Interact #1 bit
#full_tree$Leaf_Simplified %>% unique() %>% length() #66 bits

#Only 70 bits total
  
#That's only another 29 bits
full_tree$Think_Type_L0 %>% unique() %>% length() #6
full_tree$Say_Type_L0 %>% unique() %>% length() #5
full_tree$Do_Type_L0 %>% unique() %>% length() #18

```

## Data loads


```{r, echo=FALSE}
  

drops <- c(
'interact_escalate',
'interact_deescalate',
'act_uncooperative',
'act_deescalate',
'act_cooperative',
'do_interact_kind',
'do_kind',
'interact_decreasecoop',
'interact_increasecoop',
'interact_deescalate',
'act_escalate',
'condition_interact_deescalate',
'condition_interact_escalate',
'condition_interact_increasecoop',
'condition_interact_decreasecoop',
'condition_act_cooperative',
'condition_act_deescalate',
'condition_act_escalate',
'condition_act_uncooperative',
'do_interact_kind',
'interact_escalate',
'sayintkind',
'sayintkind_react',
'interact_deescalate',
'interact_decreasecoop',
'act_escalate',
'act_uncooperative',
'act_deescalate',
'act_cooperative',
'act_descalate', 
'act_escalate',
'act_uncooperative',
'interact_decreasecoop',
'interact_descalate',
'interact_deescalate', #there's a mispelling here
'interact_escalate',
'interact_increasecoop',
'thinkkind',
'sayintkind'
) %>% unique()

#sentence_variabe_agreement_minimum <- sentence_variabe_agreement 

icb_long_clean_original <- readRDS(file=paste0(here::here(), "/data/icb_long_clean.Rds")) %>% 
                            #filter(crisno==421 & sentence_number_int_aligned==16 ) %>%
                            distinct() %>%
                            mutate(variable_normalized= variable_normalized %>% str_replace("_other_clean","")) %>% #We want to collapse others in with regulars
                            mutate(variable_normalized= variable_normalized %>% str_replace("_clean","")) %>% #These only exist with actors now
                            mutate(variable_normalized= variable_normalized %>% str_replace("_other","")) %>% #Only really matters for location_other
            
                            filter(value_normalized!='drop') %>%
                            filter(email_id!='expert3') %>% #expert3 Looks broken all the time
                            #I'm going to move to a structure where event numbers can have a subsection that is condition rather than keeping it in the variable names
                            mutate(event_number_int_condition=variable_normalized %>% str_detect('condition_') %>% as.numeric() ) %>%
                            mutate(variable_normalized=variable_normalized %>% str_replace('condition_',''))  

icb_long_clean_original_393_43 <- icb_long_clean_original %>% filter(crisno==393 & sentence_number_int_aligned==43 ) %>% janitor::remove_empty() 


sentences <- icb_long_clean_original %>% dplyr::count(crisno,sentence_number_int_aligned,sentence) %>% arrange(crisno, sentence_number_int_aligned, desc(n)) %>% 
  group_by(crisno, sentence_number_int_aligned) %>% filter(row_number()==1) %>% dplyr::select(-n)

temp_wide <- icb_long_clean_original %>%
             dplyr::select(icb_survey_version, email_id,  crisno, sentence_number_int_aligned, section, sentence,event_number_int,  event_number_int_condition, variable_normalized, value_normalized) %>%
             filter(variable_normalized %in% c(
                                   'sentence_events',
                                   drops
                                   ) 
                        ) %>% distinct() %>% 
                  mutate(value_normalized= value_normalized %>% trimws() %>% tolower()) %>%
                  left_join(full_tree %>% dplyr::rename(value_normalized=Leaf)  %>%
                              mutate(value_normalized= value_normalized %>% trimws() %>% tolower()) ) 



temp_long <- temp_wide %>% 
         dplyr::select(-variable_normalized,-value_normalized) %>%
         pivot_longer(-c(icb_survey_version, email_id, crisno, sentence_number_int_aligned, section, sentence,   event_number_int,event_number_int_condition), names_to='variable_normalized' , values_to= 'value_normalized')  %>%
         filter(!is.na(value_normalized))

icb_long_clean <- icb_long_clean_original %>%
                   dplyr::select(icb_survey_version, email_id, crisno, sentence_number_int_aligned, section,  sentence,  event_number_int, event_number_int_condition, variable_normalized,value_normalized) %>%
                  rbind(temp_long) %>% distinct() %>% 
  
                  filter(!variable_normalized %in% drops)


```

# Sentence Level Agreement

Unanimous exact agreement- every expert coder chose the exact same options across all events for that question
Majority exact agreement- at least 2/3 of expert coders chose exactly the same options across all event for that question
This aggregates across conditions too


```{r}

options(warn = -1) #Groups that have no values generate max errors
#This doesn't have this yet
#event_number_int,  event_number_int_condition
temp_long <- 
  icb_long_clean  %>%
    dplyr::select(email_id,crisno,sentence_number_int_aligned, section, sentence, event_number_int, event_number_int_condition,variable_normalized, value_normalized) %>% 
    dplyr::filter(value_normalized!='' & !is.na(value_normalized)) %>%
    group_by(crisno,sentence_number_int_aligned, event_number_int_condition, variable_normalized, value_normalized) %>%
    dplyr::select(-event_number_int) %>%
    distinct() %>%
    mutate(
      email_id = email_id %>% as.factor(), 
      #crisno= crisno %>% as.factor(),
      #sentence_number_int_aligned= sentence_number_int_aligned %>% as.factor(),
      crisno_sentence_number_int_aligned= paste0(crisno, "_", sentence_number_int_aligned) %>% as.factor(), #make sure these are the only factors or it'll try to criss cross sentence number and crisno etc.
      section= section %>% as.character(),
      sentence= sentence %>% as.character(),
      variable_normalized= variable_normalized %>% as.factor()
    ) %>%
    group_by(email_id , crisno,sentence_number_int_aligned, event_number_int_condition, 
             variable_normalized,.drop=FALSE) %>% #This drop false means every coder gets a '' whether they filled in that variable or not #section, sentence going to have to ignore the sentence text for now
      summarise(value_normalized=value_normalized %>% rex_paste() ) %>%
    #that will add in dead ones now we want to split them back out
    mutate(value_normalized = value_normalized %>% str_replace_all(";;",";")) %>% 
    mutate(value_normalized = strsplit(as.character(value_normalized), ";", fixed=T)) %>% 
    unnest(value_normalized) %>%

    #add a confidence score for every token
    mutate(confidence=ifelse(variable_normalized=='raterconfidence', value_normalized, NA)) %>%
  
    mutate(confidence=confidence %>% factor(levels=c('none','low','high','complete')) %>% as.numeric() ) %>%
    mutate(confidence_expert= email_id %>% str_detect('expert') %>% ifelse(confidence,NA) %>% max(na.rm=T) ) %>%
    mutate(confidence_undergrad= email_id %>% str_detect('undergrad') %>% ifelse(confidence,NA) %>% max(na.rm=T) ) %>%

    group_by(crisno,sentence_number_int_aligned) %>%
      mutate(
        total_coders=email_id %>% unique() %>% length(),
        total_coders_expert=email_id %>% unique() %>% str_detect('expert') %>% sum() ,
        total_coders_undergrad=email_id %>% unique() %>% str_detect('undergrad') %>% sum()
      ) %>%
    ungroup() %>%
  
    #Selected By
    group_by(crisno,sentence_number_int_aligned, event_number_int_condition, variable_normalized, value_normalized) %>%
      mutate(
        selected_by_experts=email_id %>% unique() %>% str_detect('expert') %>% sum() ,
        selected_by_undergrads=email_id %>% unique() %>% str_detect('undergrad') %>% sum()
      ) %>%
    ungroup() %>%
    mutate(selected_by_any=selected_by_experts+selected_by_undergrads) %>%
    left_join(sentences) %>%
    mutate(
        selected_by_any_perc=selected_by_any/total_coders,
        selected_by_experts_perc=selected_by_experts/total_coders_expert ,
        selected_by_undergrads_perc=selected_by_undergrads/total_coders_undergrad ,
    ) %>%
    ungroup() 


#We have to compile confidence seperately
sentence_confidence_scores <- temp_long %>% 
  dplyr::select(email_id,crisno,sentence_number_int_aligned, confidence,confidence_expert,confidence_undergrad) %>% distinct() %>% 
  mutate(confidence= confidence %>% replace(., !is.finite(.), NA),
         confidence_expert = confidence_expert %>% replace(., !is.finite(.), NA),
         confidence_undergrad = confidence_undergrad %>% replace(., !is.finite(.), NA)
         ) %>% 
  dplyr::select(-email_id) %>%
  group_by(crisno, sentence_number_int_aligned) %>%
  summarise_all(mean, na.rm=T) %>%
  mutate(confidence= confidence %>% replace(., !is.finite(.), NA),
         confidence_expert = confidence_expert %>% replace(., !is.finite(.), NA),
         confidence_undergrad = confidence_undergrad %>% replace(., !is.finite(.), NA)
         ) 

codings_long <- temp_long %>%
                mutate(
                       expert_majority=(selected_by_experts>(total_coders_expert/2) & selected_by_experts>=2) %>% as.integer() ,
                       undergrad_majority= (selected_by_undergrads > (total_coders_undergrad/2) & total_coders_undergrad>=2 ) %>% as.integer()  ,
                       expert_or_undergrad_majority= ( expert_majority | (undergrad_majority & selected_by_experts>=1) ) %>% as.integer() 
                ) %>%
                group_by(crisno,sentence_number_int_aligned, variable_normalized, value_normalized) %>%
                  mutate(
                        total_coders_expert=total_coders_expert %>% replace(., is.nan(.), NA) %>% mean(na.rm=T) %>% replace(., is.nan(.), NA),
                        total_coders_undergrad=total_coders_undergrad %>% replace(., is.nan(.), NA) %>% mean(na.rm=T) %>% replace(., is.nan(.), NA)
                  ) %>%
                ungroup() %>%
                dplyr::select(-email_id) %>%
                dplyr::select(-confidence,-confidence_expert,-confidence_undergrad) %>%
                distinct() %>% #bc expert majority is maxed now these rows should be fine
                left_join(sentence_confidence_scores) %>%
                arrange(crisno,sentence_number_int_aligned, event_number_int_condition, 
                        variable_normalized, expert_majority %>% desc(), undergrad_majority %>% desc(), undergrad_majority %>% desc(), selected_by_any %>% desc() ) #event_number_int


options(warn = 1)

```

Self Reported Confidence and Percent Agreement

```{r}


confidence_totals <- bind_rows(
  icb_long_clean %>% filter(email_id %>% str_detect('expert') & variable_normalized=='raterconfidence' ) %>% count(value_normalized) %>% mutate(coder="expert") %>% mutate(n= (n/sum(n)*100) %>% round(1) %>% paste0("%") ),
  icb_long_clean %>% filter(email_id %>% str_detect('undergrad') & variable_normalized=='raterconfidence' ) %>% count(value_normalized)  %>% mutate(coder="undergrad") %>% mutate(n=(n/sum(n)*100) %>% round(1) %>% paste0("%"))
) %>%
  mutate(confidence=value_normalized %>% factor(levels=c('none','low','high','complete')) %>% as.numeric() ) %>%
  mutate(x=0.05)


library(ggExtra)
p1_confidence_agreement <- 
  bind_rows(
    codings_long %>% dplyr::select(variable_normalized, value_normalized,  confidence=confidence_expert,  selected_by_perc=selected_by_experts_perc)  %>% mutate(coder="expert"),
    codings_long %>% dplyr::select(variable_normalized, value_normalized,  confidence=confidence_undergrad,  selected_by_perc=selected_by_undergrads_perc)  %>% mutate(coder="undergrad")
  ) %>% 
    filter(value_normalized!='' & is.finite(confidence)) %>%
    filter(selected_by_perc>0) %>% #only consider tokens that were selected at all by that group
    mutate(confidence=confidence %>% round() %>% as.factor() ) %>%
    group_by(confidence, coder) %>%
      mutate(selected_by_perc_mean=selected_by_perc %>% mean(na.rm=T))  %>%
    ungroup() %>%
    ggplot(aes(x=selected_by_perc,y=confidence, color=coder ))  + geom_boxplot(notch=T) + ggtitle('Individual Self Reported Confidence Predicts Intercoder Agreement') + theme_bw() +
    theme(legend.position="bottom") +
    xlab("Percent of Coders that Selected a Token") +
    ylab("Self Reported Confidence in Sentence Coding") +
    geom_text(data=confidence_totals %>% filter(coder=="expert"), aes(label=n,x=x, y=confidence-0.1, color=coder)) +
    geom_text(data=confidence_totals %>% filter(coder=="undergrad"), aes(label=n,x=x, y=confidence+0.3, color=coder)) +
    geom_point(aes(x=selected_by_perc_mean,y=confidence, color=coder ))
p1_confidence_agreement
#ggMarginal(p1_confidence_agreement,type = "histogram", groupColour = TRUE)
```

```{r}

#These are all by definition chosen by at least 1
p_percent_chose_tag_by_concept <- 
codings_long %>% 
  filter(value_normalized!='') %>%
  filter(total_coders>1) %>% #about 9k only had one coder
  dplyr::select(variable_normalized,selected_by_any_perc,selected_by_experts_perc,selected_by_undergrads_perc) %>%
  group_by(variable_normalized) %>%
    mutate(selected_by_any_perc_mean=selected_by_any_perc %>% mean()) %>%
  ungroup() %>%
  mutate(variable_normalized=fct_reorder(variable_normalized, selected_by_any_perc_mean)) %>%
  ggplot(aes(x=selected_by_any_perc, y=variable_normalized)) + geom_boxplot() + geom_point(aes(x=selected_by_any_perc_mean), color="red") +
  xlab("Percent of All Coders") +
  ylab("Concept") +
  labs(title = "Percent of All Coders who Chose Tag by Concept"#,
        #subtitle = "Plot of length by dose",
        #caption = "Data source: ToothGrowth"
       ) + 
  theme_bw()
p_percent_chose_tag_by_concept

table(expert_majority=codings_long$expert_majority,
      undergrad_majority=codings_long$undergrad_majority)

#58% of tokens including null have agreement from either experts, undergrads, or both
(table(expert_majority=codings_long$expert_majority,
      undergrad_majority=codings_long$undergrad_majority) / nrow(codings_long) ) %>% round(2)


table(codings_long$value_normalized != "")
# FALSE   TRUE 
#480,239 408,126 #about the same number of null tokens as non null ones
```

#Agreed

```{r}

#What we could do is say if there's
codings_long_agreement <- codings_long %>%
                          mutate(keep_majority_expert= 
                                    (selected_by_experts>=2 & #selected by at least two experts
                                     expert_majority==1)   
                           ) %>%
                           mutate(keep_majority_undergrad= (selected_by_experts>=1 & expert_majority==0 & undergrad_majority==1)  %>% as.numeric() ) %>%
                           mutate(keep_majority= (keep_majority_expert | keep_majority_undergrad) %>% as.integer() ) %>%
                           group_by(crisno, sentence_number_int_aligned, event_number_int_condition, variable_normalized) %>%
                                mutate(keep_majority_max=keep_majority %>% max(na.rm=T)) %>%
                                mutate(selected_by_any_max= selected_by_any %>% max(na.rmt=T)) %>%
                           ungroup() %>%
                           mutate(keep_leftstanding = (keep_majority==0 & #Wasn't picked by a majority
                                                         selected_by_experts>=1 & #was picked by a least one expert
                                                         selected_by_any_max==selected_by_any #Has the most total votes
                                                       ) %>% as.numeric() ) %>%
                           mutate(keep = ( keep_majority==1 | keep_leftstanding==1 ) %>% as.numeric() ) 

codings_long_agreement_393_43 <- codings_long_agreement %>% filter(crisno==393 & sentence_number_int_aligned==43 ) %>% janitor::remove_empty() 
codings_long_agreement_393_59 <- codings_long_agreement %>% filter(crisno==393 & sentence_number_int_aligned==59 )
codings_long_agreement_393_38 <- codings_long_agreement %>% filter(crisno==393 & sentence_number_int_aligned==38 )
codings_long_agreement_284_16 <- codings_long_agreement %>% filter(crisno==284 & sentence_number_int_aligned==16 )

codings_long_agreed <- codings_long_agreement %>%
                           filter(value_normalized!='')  %>%
                           filter(keep==1) %>% 
                           group_by(crisno, sentence_number_int_aligned) %>%
                              mutate(no_events= max( variable_normalized=="Event_Any" & value_normalized=="no") ) %>% #make sure you do the filter or this won't twork
                           ungroup()

dim(codings_long_agreed) #249,840     19  tokens that have agreement
codings_long_agreed %>% dplyr::select(keep_majority_expert, keep_majority_undergrad, keep_majority, keep_leftstanding) %>% summarise_all(sum)




(table(expert_majority=codings_long$expert_majority,
      undergrad_majority=codings_long$undergrad_majority) / nrow(codings_long) ) %>% round(2)
#               undergrad_majority
#expert_majority    0    1
#              0 0.40 0.04
#              1 0.40 0.16


#
#
#
#Maybe we use this as a screen on the original codings and then collect what survived to make subevents?
rex_paste <- function(x){ paste0(x %>% sort() %>% unique(), collapse=";")  }
codings_wide_agreed <- icb_long_clean  %>%
                      inner_join(codings_long_agreed) %>%
                      filter(email_id %>% str_detect('expert') ) %>%
                      dplyr::select(email_id,crisno,sentence_number_int_aligned, event_number_int, event_number_int_condition, sentence,variable_normalized, value_normalized) %>%
                      pivot_wider(id_cols=c(email_id,crisno,sentence_number_int_aligned, sentence,event_number_int, event_number_int_condition), names_from=variable_normalized, values_from=value_normalized, values_fn=rex_paste) %>%
                      group_by(crisno,sentence_number_int_aligned, event_number_int_condition, sentence, say_actor_a, say_actor_b, do_actor_a, do_actor_b) %>%
                      summarise_all(rex_paste) 

codings_wide_agreed[codings_wide_agreed==""]<-NA

  
```
Validation Tests

```{r, eval=F}

keep_crisis=393
keep_sentence=38

(a <- icb_long_clean_original %>% filter(crisno==keep_crisis & sentence_number_int_aligned==keep_sentence ) %>% janitor::remove_empty()  ) #%>% View()
(b <- temp_long %>% filter(crisno==keep_crisis & sentence_number_int_aligned==keep_sentence ) %>% janitor::remove_empty()  ) #%>% View()
(c <- temp_wide %>% filter(crisno==keep_crisis & sentence_number_int_aligned==keep_sentence ) %>% janitor::remove_empty() )#%>% t()  ) #%>% View()
(d <- icb_long_clean %>% filter(crisno==keep_crisis & sentence_number_int_aligned==keep_sentence ) %>% janitor::remove_empty()  ) #%>% View()
(e <- codings_long %>% filter(crisno==keep_crisis & sentence_number_int_aligned==keep_sentence ) %>% janitor::remove_empty()  ) #%>% View()
(f <- codings_long_agreement %>% filter(crisno==keep_crisis & sentence_number_int_aligned==keep_sentence ) %>% janitor::remove_empty()   ) #%>% View()
(g <- codings_long_agreed %>% filter(crisno==keep_crisis & sentence_number_int_aligned==keep_sentence ) %>% janitor::remove_empty()   ) #%>% View()
(e <- codings_wide_agreed  %>% filter(crisno==keep_crisis & sentence_number_int_aligned==keep_sentence )  %>% janitor::remove_empty()  ) %>% t() #%>% View()

```


```{r, eval=F}

# write_csv(codings_long_agreed, paste0(here::here(), "/data_out/codings_long_agreed.csv"))
# write_csv(codings_wide_agreed, paste0(here::here(), "/data_out/codings_wide_agreed.csv"))

```


# Convert codings to sentences

```{r}

#names(codings_wide_agreed)
library(ftExtra)
library(flextable)
library(ftExtra)
library(flextable)
library(glue)

#https://github.com/tidyverse/glue/issues/42
#On why you have to include parent frame https://github.com/tidyverse/glue/issues/42
glue_rex <- function(x) glue(x, .open = "{|",.close = "|}", .envir = parent.frame()) #escape variables in the more complicated {||} syntax
events <- NULL
event_to_sentence_rex <- function(events){

  sentence <- paste0("'",events[1,]$sentence,"'")
  df_temp <- NULL
  df_temp <- data.frame(
      type = c('S','E1','E2','E3','E4','E5','E6'), 
      text = c(sentence,NA,NA,NA,NA,NA,NA)
      ) 
  
  for(i in 1:nrow(events)){
    print(i)
    e1 <- NULL
    e1 <- events[i,, drop=F]
    say=NA
    say= glue_rex("[{|e1$say_actor_a|}]{.underline shading.color='white'} made an 
                  [{|ifelse(e1$say_aggression=='more aggression','aggressive', 'unaggressive')|}]{.underline shading.color='white'} 
                  [{|e1$leaf_say_simplified|}]{.underline shading.color='white'} to 
                  [{|e1$say_actor_b|}]{.underline shading.color='white'}.") 
    
    consequence=NA
    consequence=ifelse(
      e1$consequence=="will happen",
      glue_rex("That the following will [happen]{.underline shading.color='white'}.") ,
      consquence
    )
    consequence=ifelse(
      e1$consequence=="won't happen",
      glue_rex("That if the following [won't happen]{.underline shading.color='white'}.") ,
      consequence
    )
    
    condition=NA
    condition=ifelse(
      e1$condition=="happens",
      glue_rex("If the following [happens]{.underline shading.color='white'}.") ,
      condition
    )
    condition=ifelse(
      e1$condition=="does not happen",
      glue_rex("If the following [does not happen]{.underline shading.color='white'}.") ,
      condition
    )
    
    
    do=NA
    do=ifelse(
      e1$do_Act_Interact=="Interact" & e1$event_number_int_condition==0,
      glue_rex("[{|e1$do_actor_a|}]{.underline shading.color='white'} 
                [{|ifelse(e1$do_aggression=='more aggression','aggressively', 'unaggressively')|}]{.underline shading.color='white'} 
                [{|e1$leaf_do_simplified|}]{.underline shading.color='white'} [{|e1$do_actor_b|}]{.underline shading.color='white'}.") ,
      do
    )
    do=ifelse(
      e1$do_Act_Interact=="Act" & e1$event_number_int_condition==0,
      glue_rex("[{|e1$do_actor_a|}]{.underline shading.color='white'} 
                [{|ifelse(e1$do_aggression=='more aggression','aggressively', 'unaggressively')|}]{.underline shading.color='white'} 
                [{|e1$leaf_do_simplified|}]{.underline shading.color='white'}.")  ,
      do
    )
    
    do=ifelse(
      e1$do_Act_Interact=="Interact" & e1$event_number_int_condition==1,
      glue_rex("(Condition) [{|e1$do_actor_a|}]{.underline shading.color='white'} 
                [{|ifelse(e1$do_aggression=='more aggression','aggressively', 'unaggressively')|}]{.underline shading.color='white'} 
                [{|e1$leaf_do_simplified|}]{.underline shading.color='white'} [{|e1$do_actor_b|}]{.underline shading.color='white'}.") ,
      do
    )
    do=ifelse(
      e1$do_Act_Interact=="Act" & e1$event_number_int_condition==1,
      glue_rex("(Condition) [{|e1$do_actor_a|}]{.underline shading.color='white'} 
                [{|ifelse(e1$do_aggression=='more aggression','aggressively', 'unaggressively')|}]{.underline shading.color='white'} 
                [{|e1$leaf_do_simplified|}]{.underline shading.color='white'}.")  ,
      do
    )
    
    
    final_coding=NA
    final_coding = ifelse(
      e1$Behavior=="Do",
      glue_rex("{|do|}"),
      final_coding
    )
    final_coding = ifelse(
      e1$Behavior=="Do;Say",
      glue_rex("{|say|} {|do|})"),
      final_coding
    )

    final_coding = ifelse(
      e1$Behavior=="Do;Say" & !is.na(consequence),
      glue_rex("{|say|} {|consequence|} {|do|}"),
      final_coding
    )
    final_coding = ifelse(
      e1$Behavior=="Do;Say" & !is.na(consequence) & !is.na(condition),
      glue_rex("{|say|} {|consequence|} {|do|} {|condition|}"),
      final_coding
    )
  
    if(length(final_coding)>0){
     df_temp$text[i+1] <- final_coding
    } else {next}
    #print(df_temp)
  }
  #print(df_temp)
  return(df_temp %>% mutate(text=text %>% as.character() )  %>% na.omit())
}

df_final <- NA
events1 <- codings_wide_agreed  %>% filter(crisno==keep_crisis & sentence_number_int_aligned==keep_sentence )  %>% janitor::remove_empty()  
asdfasdf <- event_to_sentence_rex(events1)

df_temp %>%
  dplyr::select(-type) %>%
  na.omit() %>%
  as_flextable() %>%
  colformat_md() %>% 
  width(width = 8)

```



# Old Ideas

```{r echo=FALSE, include=T, eval=F}

library(janitor)
#table(icb_wide_clean$email_id )
icb_wide_clean$email_id_expert <- icb_wide_clean$email_id %>% str_detect("grad|postgrad")

#icb_wide_clean$email_id_expert 
#icb_wide_clean$raterconfidence
#icb_wide_clean$raterconfidence_reason

icb_wide_clean %>% 
  tabyl(email_id_expert, raterconfidence, show_na = FALSE) %>%
  adorn_percentages("row") %>% 
  adorn_pct_formatting(digits = 2) %>%
  adorn_ns()

icb_wide_clean  %>%
    mutate(raterconfidence_reason = raterconfidence_reason %>% str_replace_all("other|;","") %>% trimws() ) %>%
    filter(raterconfidence_reason!='')  %>%
    tabyl(raterconfidence_reason, show_na = FALSE) %>%
    arrange(desc(n)) %>%
    head() %>%
    mutate(percent=percent %>% round(2))

icb_long_clean$email_id_expert <- icb_long_clean$email_id %>% str_detect("grad|postgrad")

temp <- icb_long_clean %>%
        dplyr::select(email_id, email_id_expert, crisno, sentence_number_int_aligned, variable, value) %>%
        filter(!variable %in% c('date','say_actor_a','say_actor_b','do_actor_a','do_actor_b','think_actor_a','think_sentence_events','do_timing_reorder','sayintkind_react','do_timing_reorder',
                                'coder_crisis_order','point_in_time','start_time','end_time','earliest_date','preceding_event',
                                'act_cooperative','act_descalate act_escalate', 'act_uncooperative', 'interact_decreasecoop', 'interact_descalate', 'interact_escalate', 'interact_increasecoop',
                                'act_descalate','act_escalate','thinkkind','act_descalate','act_escalate','raterconfidence_reason_survey','raterconfidence_reason') &
                 !variable %>% str_detect("condition|actor|location_other|date|time")
               ) 

var_names <- temp %>% pull(variable) %>% unique()
library(fastDummies)
temp_wide <- temp %>% mutate(variable_value=paste0(variable,";",value)) %>% dplyr::select(-variable,-value) %>% dummy_cols(select_columns='variable_value', remove_selected_columns=T) 
dim(temp_wide)

temp_mean_expert <- temp_wide %>%
                    group_by(email_id_expert,email_id,crisno,sentence_number_int_aligned) %>% #max for that person across all events they found
                    summarise_if(is.numeric, max) %>%
                    dplyr::select(-email_id) %>%
                    group_by(email_id_expert,crisno,sentence_number_int_aligned) %>% #max for that person across all events they found
                    summarise_if(is.numeric, mean) %>%
                    ungroup()

temp_mean_expert_lomg <- temp_mean_expert %>%
                          filter(email_id_expert==T) %>%
                          ungroup() %>%
                          dplyr::select(-email_id_expert) %>% #,-email_id
                          pivot_longer(cols=-c(crisno,sentence_number_int_aligned)) %>%
                          mutate(value= abs(value-0.5)*2) %>% #0 means completely disagree 1 means completely agree
                          group_by(name) %>%
                          summarise(value=mean(value))

#only positives
temp_mean_expert_lomg_onlypos <- temp_mean_expert %>%
                                filter(email_id_expert==T) %>%
                                ungroup() %>%
                                dplyr::select(-email_id_expert) %>%
                                pivot_longer(cols=-c(crisno,sentence_number_int_aligned)) %>%
                                filter(value>0) %>% #only consider agreement when at least one coder uses the tag in that sentence
                                mutate(value= abs(value-0.5)*2) %>% #0 means completely disagree 1 means completely agree
                                rename(agreement=value) %>%
                                separate(name, c("variable", "value"), ";" ) %>%
                                group_by(variable) %>%
                                mutate(agreement_a=mean(agreement)) %>%
                                group_by(variable,value) %>%
                                mutate(agreement_b=mean(agreement)) %>%
                                ungroup() %>%
                                dplyr::select(-crisno, -sentence_number_int_aligned, -agreement) %>%
                                distinct()

#Confidence
temp2_confidence <- icb_long_clean %>%
                      dplyr::select(email_id, email_id_expert, crisno, sentence_number_int_aligned, raterconfidence, variable, value) %>%
                      filter(email_id_expert==T) %>%
                      filter(!variable %in% c('date','say_actor_a','say_actor_b','do_actor_a','do_actor_b','think_actor_a','think_sentence_events','do_timing_reorder','sayintkind_react','do_timing_reorder',
                                              'coder_crisis_order','point_in_time','start_time','end_time','earliest_date','preceding_event',
                                              'act_cooperative','act_descalate act_escalate', 'act_uncooperative', 'interact_decreasecoop', 'interact_descalate', 'interact_escalate', 'interact_increasecoop',
                                              'act_descalate','act_escalate','thinkkind','act_descalate','act_escalate','raterconfidence_reason_survey','raterconfidence_reason') &
                               !variable %>% str_detect("condition|actor|location_other|date|time")
                             ) %>%
                      mutate(raterconfidence=factor(raterconfidence, levels=c('None', 'Low', 'High',  'Complete') )) %>% 
                      group_by(variable) %>%
                      mutate(raterconfidence_a=raterconfidence %>% as.numeric() %>% mean(na.rm=T) %>% round(2)) %>%
                      group_by(variable, value) %>%
                      mutate(raterconfidence_b=raterconfidence %>% as.numeric() %>% mean(na.rm=T) %>% round(2)) %>%
                      ungroup() %>%
                      dplyr::select(-email_id, -email_id_expert, -crisno, -sentence_number_int_aligned, -raterconfidence) %>%
                      distinct()

```


```{r, eval=F, echo=F, results='markup', include=T, message=F, cache=F, ft.arraystretch=0.75}

intercoder_agreement_and_confidence_by_item <- temp_mean_expert_lomg_onlypos %>% 
                  mutate(variable=variable %>% str_replace_all("variable_value_|clean",""))  %>%
                  mutate(variable=variable %>% str_replace_all("_",""))  %>%
                  left_join(temp2_confidence %>% 
                                    mutate(variable=variable %>% str_replace_all("variable_value_|clean",""))  %>%
                                    mutate(variable=variable %>% str_replace_all("_","")) 
                            ) %>%
                  dplyr::arrange(desc(agreement_a), desc(agreement_b)) %>%
                  mutate(agreement_a=agreement_a %>% round(3)) %>% 
                  mutate(agreement_b=agreement_b %>% round(3)) 

intercoder_agreement_and_confidence_by_item %>%
                  flextable::as_flextable() %>%
                  flextable::bg( i = which( 1:nrow(temp_mean_expert_lomg_onlypos) %% 2 == 1), part = "body", bg = "#EFEFEF") %>%
                  #merge_v(part = "body") %>% 
                  #flextable::width( j = 1, width=7) %>%
                  flextable::fontsize(size = 6, part = "body") %>%
                  #flextable::line_spacing( space = 0.5, part = "body") %>% #i=1:nrow(lit_review_alt),
                  flextable::padding(padding = 0, part = "body")  %>%
                  flextable::merge_v(part = "body", combine = FALSE) 

#Note Average intercoder agreement and self reported confidence look uncorrelated at the item level. I think it's because they're correlated at the sentence level, not the item level.
intercoder_agreement_and_confidence_by_item %>%
  ggplot(aes(x=agreement_b,y=raterconfidence_b)) +
  geom_point() + geom_smooth()

```


```{r, eval=F}

temp_jaccard <- icb_long_clean %>%
                      filter(email_id_expert==T) %>%
                      dplyr::select(email_id,  crisno, sentence_number_int_aligned,  variable, value) %>%
                      
                      filter(!variable %in% c('date','say_actor_a','say_actor_b','do_actor_a','do_actor_b','think_actor_a','think_sentence_events','do_timing_reorder','sayintkind_react','do_timing_reorder',
                                              'coder_crisis_order','point_in_time','start_time','end_time','earliest_date','preceding_event',
                                              'act_cooperative','act_descalate act_escalate', 'act_uncooperative', 'interact_decreasecoop', 'interact_descalate', 'interact_escalate', 'interact_increasecoop',
                                              'act_descalate','act_escalate','thinkkind','act_descalate','act_escalate','raterconfidence_reason_survey','raterconfidence_reason') &
                               !variable %>% str_detect("condition|actor|location_other|date|time")
                             )

library(fastDummies)
temp_jaccard_wide <- temp_jaccard %>% mutate(variable_value=paste0(variable,";",value)) %>% dplyr::select(-variable,-value) %>% dummy_cols(select_columns='variable_value', remove_selected_columns=T) 
dim(temp_jaccard_wide)

temp_jaccard_wide %>% 
  #group_by(email_id,crisno,sentence_number_int_aligned) %>%
  pivot_longer(-c(email_id,crisno,sentence_number_int_aligned)) %>%
  arrange(email_id,crisno,sentence_number_int_aligned, name) %>%
  summarise()


```



